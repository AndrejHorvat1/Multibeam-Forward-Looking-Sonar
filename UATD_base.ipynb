{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAdM3u2Wx6HC2aoUSWmtga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrejHorvat1/Multibeam-Forward-Looking-Sonar/blob/main/UATD_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "557ZDkYLdyCG",
        "outputId": "822cd782-1dd1-4ca7-b1a3-7cdaea5478a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#povezivanje s driveom\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_image_dir_train = \"/content/drive/MyDrive/UATD_YOLO_Dataset_v2/images/train\"\n",
        "drive_label_dir_train = \"/content/drive/MyDrive/UATD_YOLO_Dataset_v2/labels/train\"\n",
        "drive_image_dir_val = \"/content/drive/MyDrive/UATD_YOLO_Dataset_v2/images/val\"\n",
        "drive_label_dir_val = \"/content/drive/MyDrive/UATD_YOLO_Dataset_v2/labels/val\""
      ],
      "metadata": {
        "id": "DSbOEqSTfpV2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJSWXwoR1fJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "def prepare_base_dataset(drive_image_dir_train, drive_label_dir_train,\n",
        "                          drive_image_dir_val, drive_label_dir_val,\n",
        "                          colab_base_path=\"/content/UATD_YOLO_BASE\"):\n",
        "\n",
        "    os.makedirs(f\"{colab_base_path}/images/train\", exist_ok=True)\n",
        "    os.makedirs(f\"{colab_base_path}/labels/train\", exist_ok=True)\n",
        "    os.makedirs(f\"{colab_base_path}/images/val\", exist_ok=True)\n",
        "    os.makedirs(f\"{colab_base_path}/labels/val\", exist_ok=True)\n",
        "\n",
        "    def copy_original_files(src_dir, dst_dir):\n",
        "        for file_path in glob(os.path.join(src_dir, \"*\")):\n",
        "            filename = os.path.basename(file_path)\n",
        "            if \"_aug\" not in filename:\n",
        "                shutil.copy(file_path, dst_dir)\n",
        "\n",
        "    copy_original_files(drive_image_dir_train, f\"{colab_base_path}/images/train\")\n",
        "    copy_original_files(drive_label_dir_train, f\"{colab_base_path}/labels/train\")\n",
        "    copy_original_files(drive_image_dir_val, f\"{colab_base_path}/images/val\")\n",
        "    copy_original_files(drive_label_dir_val, f\"{colab_base_path}/labels/val\")\n",
        "\n",
        "    print(\"Podaci kopirani u Colab workspace\")"
      ],
      "metadata": {
        "id": "6FMWFvoUf94j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepare_base_dataset(drive_image_dir_train, drive_label_dir_train,\n",
        "                     drive_image_dir_val, drive_label_dir_val)"
      ],
      "metadata": {
        "id": "tISBq5FugSkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea14dc6-c9f9-403d-d919-96975194ca7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Podaci kopirani u Colab workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/UATD_YOLO_Dataset_Test_v2\" /content/"
      ],
      "metadata": {
        "id": "VIlVm4O-hIXZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = \"\"\"train: /content/UATD_YOLO_BASE/images/train\n",
        "val: /content/UATD_YOLO_BASE/images/val\n",
        "nc: 10\n",
        "test:\n",
        "  - /content/UATD_YOLO_Dataset_Test_v2/images/test_set1\n",
        "  - /content/UATD_YOLO_Dataset_Test_v2/images/test_set2\n",
        "names: ['cube', 'ball', 'cylinder', 'human body', 'plane', 'circle cage', 'square cage', 'metal bucket', 'tyre', 'rov']\n",
        "\"\"\"\n",
        "\n",
        "os.makedirs(\"yolo_dataset\", exist_ok=True)\n",
        "\n",
        "with open(\"yolo_dataset/data.yaml\", \"w\") as f:\n",
        "    f.write(data_yaml)"
      ],
      "metadata": {
        "id": "frV2rZEbm5WO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdb-4dWwnGyN",
        "outputId": "9259029f-a29a-476c-d3c8-ac13f23dbd6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.127-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.127-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.127 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Konfiguracija\n",
        "DATA_YAML_PATH = \"yolo_dataset/data.yaml\"\n",
        "BEST_MODEL_PATH = \"best_yolov8.pt\"\n",
        "INITIAL_WEIGHTS = \"yolov8s.pt\"\n",
        "EPOCHS = 15\n",
        "\n",
        "# Inicijaliziraj model\n",
        "model = YOLO(INITIAL_WEIGHTS)\n",
        "map_scores = []\n",
        "best_map = 0.0\n",
        "\n",
        "# Loop po epohama\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n Epoha {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    # Treniraj samo 1 epohu\n",
        "    model.train(data=DATA_YAML_PATH, epochs=1, batch=8, imgsz=640, project=\"runs\", name=\"custom_loop\", exist_ok=True)\n",
        "\n",
        "    # Validacija na test skupu\n",
        "    metrics = model.val(data=DATA_YAML_PATH, split=\"test\", imgsz=640, batch=8)\n",
        "\n",
        "    # Dohvati mAP@0.5 i dodaj u listu\n",
        "    map_50 = metrics.box.map50  # float\n",
        "    print(f\"mAP@0.5 test: {map_50:.4f}\")\n",
        "    map_scores.append(map_50)\n",
        "\n",
        "\n",
        "# Plotanje rezultata\n",
        "plt.plot(range(1, EPOCHS + 1), map_scores, marker='o')\n",
        "plt.title(\"mAP@0.5 na test skupu kroz epohe\")\n",
        "plt.xlabel(\"Epoha\")\n",
        "plt.ylabel(\"mAP@0.5\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oUjw_Y1_nn0c",
        "outputId": "a0c12177-18aa-4422-b893-91ddad70c360"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 266MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoha 1/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 27.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 104MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 77.8Â±22.5 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:13<00:00, 437.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/UATD_YOLO_BASE/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 60.0Â±19.9 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:03<00:00, 442.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/UATD_YOLO_BASE/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.95G      1.978      2.786      1.203         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:52<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:22<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.702      0.619       0.67      0.305\n",
            "\n",
            "1 epochs completed in 0.055 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.707       0.62      0.673      0.306\n",
            "                  cube        525        526      0.609      0.821      0.758      0.363\n",
            "                  ball        605        606      0.866      0.764      0.869       0.42\n",
            "              cylinder        113        113      0.627      0.646      0.624      0.272\n",
            "            human body        278        279      0.708      0.819      0.828      0.359\n",
            "                 plane        167        167      0.691      0.469      0.659      0.333\n",
            "           circle cage        141        142      0.872      0.481      0.627      0.333\n",
            "           square cage        188        188      0.909      0.457      0.656      0.249\n",
            "          metal bucket         97         97      0.728      0.515      0.659      0.296\n",
            "                  tyre        227        229      0.655      0.467      0.521      0.265\n",
            "                   rov        130        130      0.406      0.762      0.526      0.172\n",
            "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 72.1Â±27.0 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:03<00:00, 439.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:25<00:00,  7.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323       0.56       0.49      0.535      0.207\n",
            "                  cube        338        338      0.315       0.82      0.495      0.152\n",
            "                  ball        390        390      0.796      0.818      0.861      0.415\n",
            "              cylinder         93         93      0.435      0.452      0.429       0.14\n",
            "            human body        149        149      0.504      0.752      0.706      0.289\n",
            "                 plane        269        269      0.678      0.491      0.639      0.304\n",
            "           circle cage        197        197      0.873       0.21      0.524      0.203\n",
            "           square cage        335        335      0.617     0.0866      0.337      0.105\n",
            "          metal bucket         11         11      0.208     0.0909      0.168     0.0464\n",
            "                  tyre        241        241      0.702      0.419      0.574      0.229\n",
            "                   rov        300        300      0.469       0.76      0.618      0.184\n",
            "Speed: 0.5ms preprocess, 7.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.5351\n",
            "\n",
            " Epoha 2/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2947.2Â±739.2 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1028.3Â±862.8 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      2.12G      2.004       2.32       1.22         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:50<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:21<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.804       0.71      0.816      0.385\n",
            "\n",
            "1 epochs completed in 0.055 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.805      0.709      0.817      0.385\n",
            "                  cube        525        526      0.658      0.901      0.872      0.399\n",
            "                  ball        605        606      0.892      0.835        0.9      0.431\n",
            "              cylinder        113        113      0.774      0.513       0.69      0.319\n",
            "            human body        278        279      0.698      0.878      0.844      0.364\n",
            "                 plane        167        167      0.872      0.734      0.869      0.436\n",
            "           circle cage        141        142      0.889      0.521      0.741      0.378\n",
            "           square cage        188        188      0.906      0.564      0.833      0.379\n",
            "          metal bucket         97         97      0.761      0.952      0.938      0.449\n",
            "                  tyre        227        229      0.826      0.603      0.754      0.399\n",
            "                   rov        130        130       0.77      0.592      0.726      0.297\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2471.3Â±705.2 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:25<00:00,  7.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.693      0.606      0.695      0.279\n",
            "                  cube        338        338      0.366      0.822      0.611       0.19\n",
            "                  ball        390        390      0.794      0.854      0.867      0.435\n",
            "              cylinder         93         93      0.482      0.301      0.393      0.127\n",
            "            human body        149        149      0.452      0.859      0.727      0.256\n",
            "                 plane        269        269      0.858      0.673      0.827      0.437\n",
            "           circle cage        197        197      0.872      0.276      0.631      0.273\n",
            "           square cage        335        335      0.662      0.175      0.415      0.122\n",
            "          metal bucket         11         11      0.728      0.909      0.917      0.302\n",
            "                  tyre        241        241      0.858      0.602      0.789      0.367\n",
            "                   rov        300        300      0.859       0.59       0.77      0.284\n",
            "Speed: 0.4ms preprocess, 7.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.6947\n",
            "\n",
            " Epoha 3/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2267.0Â±298.2 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 482.1Â±298.7 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.94G      1.707      1.291      1.107         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:46<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:21<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.834      0.783      0.875      0.426\n",
            "\n",
            "1 epochs completed in 0.053 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.832      0.784      0.873      0.427\n",
            "                  cube        525        526      0.751      0.899      0.912      0.462\n",
            "                  ball        605        606      0.878      0.904      0.936       0.47\n",
            "              cylinder        113        113      0.786      0.779      0.842       0.36\n",
            "            human body        278        279      0.724      0.921        0.9      0.423\n",
            "                 plane        167        167      0.945      0.612      0.878       0.49\n",
            "           circle cage        141        142      0.881      0.628      0.808      0.431\n",
            "           square cage        188        188      0.919      0.664      0.866      0.395\n",
            "          metal bucket         97         97      0.791      0.948       0.94      0.453\n",
            "                  tyre        227        229      0.816      0.734      0.824      0.449\n",
            "                   rov        130        130      0.831      0.754      0.829      0.333\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2512.5Â±809.0 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:25<00:00,  7.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323       0.78      0.648      0.742      0.315\n",
            "                  cube        338        338      0.507      0.817      0.613      0.213\n",
            "                  ball        390        390      0.819      0.872      0.873      0.436\n",
            "              cylinder         93         93      0.724      0.763      0.784      0.287\n",
            "            human body        149        149      0.536      0.839      0.703      0.285\n",
            "                 plane        269        269      0.952      0.584      0.831      0.482\n",
            "           circle cage        197        197      0.896      0.349      0.606      0.272\n",
            "           square cage        335        335      0.735      0.203      0.512      0.169\n",
            "          metal bucket         11         11      0.869      0.818      0.892      0.316\n",
            "                  tyre        241        241      0.872      0.596        0.8      0.378\n",
            "                   rov        300        300      0.888      0.634      0.805      0.308\n",
            "Speed: 0.5ms preprocess, 7.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7417\n",
            "\n",
            " Epoha 4/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2047.7Â±516.6 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 615.5Â±64.8 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.94G      1.585      1.041      1.064         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:47<00:00,  4.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.838      0.788      0.874      0.426\n",
            "\n",
            "1 epochs completed in 0.053 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.833      0.798      0.874      0.426\n",
            "                  cube        525        526      0.842      0.891      0.933      0.455\n",
            "                  ball        605        606      0.823      0.914      0.924      0.462\n",
            "              cylinder        113        113      0.867      0.692      0.787      0.329\n",
            "            human body        278        279      0.714       0.92      0.909       0.43\n",
            "                 plane        167        167      0.895      0.871       0.95       0.56\n",
            "           circle cage        141        142      0.873      0.483      0.723      0.376\n",
            "           square cage        188        188       0.96      0.639      0.872      0.399\n",
            "          metal bucket         97         97      0.872      0.917      0.939      0.436\n",
            "                  tyre        227        229      0.733       0.79      0.826      0.443\n",
            "                   rov        130        130      0.755      0.862      0.875      0.374\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2182.4Â±594.1 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.743      0.643      0.741      0.312\n",
            "                  cube        338        338      0.527      0.778      0.659      0.232\n",
            "                  ball        390        390      0.747      0.877      0.862      0.421\n",
            "              cylinder         93         93      0.937      0.478      0.831      0.297\n",
            "            human body        149        149      0.416      0.852      0.626      0.246\n",
            "                 plane        269        269      0.874      0.822      0.928      0.534\n",
            "           circle cage        197        197      0.913      0.267      0.532       0.24\n",
            "           square cage        335        335       0.75      0.188      0.561      0.187\n",
            "          metal bucket         11         11      0.586      0.727        0.8      0.262\n",
            "                  tyre        241        241       0.85      0.689      0.801      0.363\n",
            "                   rov        300        300      0.831      0.756       0.81      0.334\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7410\n",
            "\n",
            " Epoha 5/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2157.5Â±289.7 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 697.1Â±71.4 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.94G      1.497     0.9131      1.036         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:50<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:21<00:00,  4.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.869      0.798      0.889      0.426\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477       0.87      0.802      0.891      0.427\n",
            "                  cube        525        526      0.891      0.874      0.925      0.449\n",
            "                  ball        605        606      0.921      0.888      0.943      0.455\n",
            "              cylinder        113        113      0.886      0.691      0.803      0.333\n",
            "            human body        278        279      0.724      0.949      0.918       0.44\n",
            "                 plane        167        167       0.93      0.874      0.954      0.528\n",
            "           circle cage        141        142      0.885      0.599      0.843      0.424\n",
            "           square cage        188        188      0.947      0.707      0.875       0.39\n",
            "          metal bucket         97         97      0.809      0.928      0.927      0.438\n",
            "                  tyre        227        229      0.865      0.701      0.827      0.445\n",
            "                   rov        130        130      0.843      0.808      0.893      0.364\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2516.8Â±781.6 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:23<00:00,  8.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.769      0.654      0.738      0.304\n",
            "                  cube        338        338      0.587       0.76      0.653      0.224\n",
            "                  ball        390        390      0.872      0.846      0.886      0.416\n",
            "              cylinder         93         93      0.946      0.565      0.819      0.284\n",
            "            human body        149        149      0.395      0.879      0.615      0.236\n",
            "                 plane        269        269        0.9      0.838      0.915      0.495\n",
            "           circle cage        197        197      0.919      0.287      0.507      0.227\n",
            "           square cage        335        335      0.751      0.198      0.532      0.189\n",
            "          metal bucket         11         11      0.608      0.909      0.866      0.295\n",
            "                  tyre        241        241       0.83      0.598      0.762      0.354\n",
            "                   rov        300        300      0.884      0.659      0.824      0.324\n",
            "Speed: 0.4ms preprocess, 6.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7379\n",
            "\n",
            " Epoha 6/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2775.9Â±806.8 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 541.2Â±79.2 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G       1.42     0.8317      1.012         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:49<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477       0.83      0.805      0.871      0.414\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.829      0.806      0.872      0.415\n",
            "                  cube        525        526      0.888      0.878      0.933      0.455\n",
            "                  ball        605        606      0.889      0.893      0.922       0.43\n",
            "              cylinder        113        113      0.838      0.717      0.777      0.316\n",
            "            human body        278        279      0.504      0.961      0.858      0.414\n",
            "                 plane        167        167      0.954      0.879      0.959      0.519\n",
            "           circle cage        141        142      0.882      0.683       0.83      0.417\n",
            "           square cage        188        188      0.948      0.674      0.893      0.439\n",
            "          metal bucket         97         97      0.799      0.866      0.922      0.419\n",
            "                  tyre        227        229      0.814      0.727      0.812       0.44\n",
            "                   rov        130        130      0.772      0.785      0.812      0.301\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2041.7Â±463.3 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:23<00:00,  8.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.697      0.671      0.702      0.267\n",
            "                  cube        338        338      0.565      0.834      0.619      0.191\n",
            "                  ball        390        390      0.757      0.869      0.859      0.383\n",
            "              cylinder         93         93       0.85      0.672      0.814       0.28\n",
            "            human body        149        149      0.206      0.872      0.549      0.212\n",
            "                 plane        269        269      0.878      0.885      0.923      0.477\n",
            "           circle cage        197        197      0.776       0.36      0.523      0.226\n",
            "           square cage        335        335      0.747      0.229      0.493      0.156\n",
            "          metal bucket         11         11      0.614      0.636      0.675       0.15\n",
            "                  tyre        241        241      0.832      0.577       0.77      0.313\n",
            "                   rov        300        300      0.744       0.77      0.798      0.284\n",
            "Speed: 0.3ms preprocess, 7.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7023\n",
            "\n",
            " Epoha 7/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2391.6Â±478.1 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 619.6Â±26.4 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.94G      1.356      0.767     0.9914         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:49<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.865      0.774      0.868      0.417\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.866      0.772      0.868      0.416\n",
            "                  cube        525        526      0.894      0.832      0.915      0.456\n",
            "                  ball        605        606      0.903      0.889       0.92      0.438\n",
            "              cylinder        113        113      0.847      0.673      0.767      0.341\n",
            "            human body        278        279      0.724      0.935      0.912      0.453\n",
            "                 plane        167        167      0.907      0.898      0.955      0.492\n",
            "           circle cage        141        142      0.852      0.563      0.744      0.361\n",
            "           square cage        188        188      0.962      0.713      0.886      0.394\n",
            "          metal bucket         97         97      0.903      0.804      0.909      0.432\n",
            "                  tyre        227        229      0.821      0.616      0.761      0.391\n",
            "                   rov        130        130      0.845      0.792       0.91        0.4\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2306.4Â±526.0 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:23<00:00,  8.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.698       0.67      0.684      0.264\n",
            "                  cube        338        338       0.53      0.772      0.524      0.169\n",
            "                  ball        390        390      0.687      0.882      0.828      0.378\n",
            "              cylinder         93         93      0.781       0.71      0.817       0.27\n",
            "            human body        149        149      0.439      0.893      0.719      0.275\n",
            "                 plane        269        269      0.858      0.918      0.938      0.496\n",
            "           circle cage        197        197      0.634       0.29      0.421      0.161\n",
            "           square cage        335        335      0.744      0.364      0.491       0.13\n",
            "          metal bucket         11         11      0.714      0.455      0.495      0.131\n",
            "                  tyre        241        241      0.762      0.637      0.747      0.273\n",
            "                   rov        300        300      0.828      0.783      0.863      0.355\n",
            "Speed: 0.4ms preprocess, 7.0ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.6843\n",
            "\n",
            " Epoha 8/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2797.3Â±495.4 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 596.5Â±48.8 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G      1.298     0.7182     0.9745         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:49<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:20<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.842      0.809      0.879      0.425\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.845      0.806      0.879      0.425\n",
            "                  cube        525        526      0.807       0.93      0.914      0.449\n",
            "                  ball        605        606      0.895      0.909      0.936      0.435\n",
            "              cylinder        113        113      0.768      0.814      0.814      0.378\n",
            "            human body        278        279      0.796      0.864      0.902      0.416\n",
            "                 plane        167        167      0.914      0.958      0.977       0.56\n",
            "           circle cage        141        142      0.793      0.593      0.758      0.363\n",
            "           square cage        188        188       0.93      0.723       0.87      0.365\n",
            "          metal bucket         97         97      0.895      0.907      0.971      0.482\n",
            "                  tyre        227        229      0.771      0.705      0.773      0.401\n",
            "                   rov        130        130      0.886      0.657      0.871      0.396\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2019.3Â±613.4 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.754      0.638      0.692      0.267\n",
            "                  cube        338        338      0.484      0.769      0.483      0.146\n",
            "                  ball        390        390       0.78      0.862      0.819      0.381\n",
            "              cylinder         93         93      0.769      0.789      0.821      0.285\n",
            "            human body        149        149      0.807      0.859      0.848      0.354\n",
            "                 plane        269        269      0.892      0.918      0.949      0.534\n",
            "           circle cage        197        197      0.786      0.234      0.489      0.179\n",
            "           square cage        335        335      0.659      0.265      0.337     0.0804\n",
            "          metal bucket         11         11      0.667      0.455      0.605      0.116\n",
            "                  tyre        241        241      0.777      0.639      0.729      0.253\n",
            "                   rov        300        300      0.916      0.585      0.838      0.343\n",
            "Speed: 0.4ms preprocess, 7.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.6919\n",
            "\n",
            " Epoha 9/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2169.9Â±385.5 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 823.8Â±474.8 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G      1.245     0.6799     0.9596         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:50<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.847      0.797      0.881      0.423\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477       0.85      0.795      0.881      0.423\n",
            "                  cube        525        526      0.837      0.918      0.932      0.428\n",
            "                  ball        605        606       0.88      0.904      0.931      0.436\n",
            "              cylinder        113        113      0.715      0.778      0.786      0.347\n",
            "            human body        278        279      0.778      0.918       0.92      0.419\n",
            "                 plane        167        167      0.857      0.966      0.967      0.567\n",
            "           circle cage        141        142      0.863      0.575      0.786      0.361\n",
            "           square cage        188        188      0.959      0.751      0.893      0.397\n",
            "          metal bucket         97         97       0.95      0.787      0.938      0.438\n",
            "                  tyre        227        229      0.731        0.7      0.763      0.413\n",
            "                   rov        130        130      0.934      0.649      0.898      0.428\n",
            "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2314.4Â±703.8 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.766       0.67       0.71      0.275\n",
            "                  cube        338        338      0.475      0.766      0.467      0.142\n",
            "                  ball        390        390      0.719      0.885      0.843      0.374\n",
            "              cylinder         93         93      0.775       0.86      0.861      0.295\n",
            "            human body        149        149      0.685      0.879      0.812       0.33\n",
            "                 plane        269        269      0.861      0.941       0.95      0.532\n",
            "           circle cage        197        197      0.797       0.28      0.473      0.184\n",
            "           square cage        335        335      0.684      0.355      0.444      0.115\n",
            "          metal bucket         11         11          1      0.442      0.659      0.129\n",
            "                  tyre        241        241      0.719      0.733      0.768      0.295\n",
            "                   rov        300        300      0.944      0.561      0.818       0.35\n",
            "Speed: 0.5ms preprocess, 7.0ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7096\n",
            "\n",
            " Epoha 10/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2300.0Â±256.9 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 717.3Â±73.9 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.95G      1.218     0.6582     0.9492         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:48<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.843      0.834       0.89      0.438\n",
            "\n",
            "1 epochs completed in 0.053 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:20<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.844      0.835       0.89      0.438\n",
            "                  cube        525        526      0.921      0.887      0.944      0.485\n",
            "                  ball        605        606      0.888      0.932      0.947      0.483\n",
            "              cylinder        113        113      0.573       0.85      0.757      0.311\n",
            "            human body        278        279      0.799      0.953      0.947      0.454\n",
            "                 plane        167        167       0.93      0.951      0.971       0.53\n",
            "           circle cage        141        142      0.905      0.604      0.812      0.413\n",
            "           square cage        188        188      0.955      0.791      0.919      0.427\n",
            "          metal bucket         97         97       0.92      0.825      0.944      0.486\n",
            "                  tyre        227        229      0.679      0.775      0.796      0.434\n",
            "                   rov        130        130      0.871       0.78      0.865      0.355\n",
            "Speed: 0.2ms preprocess, 3.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2372.5Â±649.8 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.733      0.682      0.737      0.301\n",
            "                  cube        338        338      0.579      0.799      0.577      0.202\n",
            "                  ball        390        390      0.738      0.897      0.852      0.429\n",
            "              cylinder         93         93      0.542      0.903      0.853      0.337\n",
            "            human body        149        149      0.584      0.859      0.784       0.33\n",
            "                 plane        269        269      0.878      0.937      0.945      0.521\n",
            "           circle cage        197        197      0.789      0.209      0.527       0.21\n",
            "           square cage        335        335       0.78      0.355      0.592      0.179\n",
            "          metal bucket         11         11      0.853       0.53      0.705      0.186\n",
            "                  tyre        241        241      0.713      0.685      0.746      0.311\n",
            "                   rov        300        300      0.873      0.643      0.787      0.305\n",
            "Speed: 0.4ms preprocess, 7.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7369\n",
            "\n",
            " Epoha 11/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2783.4Â±668.0 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 621.2Â±52.7 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G      1.175     0.6303     0.9369         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:49<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:21<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.889      0.837      0.904      0.443\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.888      0.834      0.903      0.443\n",
            "                  cube        525        526      0.904      0.914      0.939      0.474\n",
            "                  ball        605        606      0.966      0.851      0.946      0.489\n",
            "              cylinder        113        113      0.748       0.85      0.823      0.344\n",
            "            human body        278        279      0.876      0.907      0.939      0.459\n",
            "                 plane        167        167      0.895      0.946      0.964      0.508\n",
            "           circle cage        141        142      0.918      0.634      0.812      0.417\n",
            "           square cage        188        188      0.964      0.853      0.933      0.445\n",
            "          metal bucket         97         97      0.947      0.916      0.983      0.519\n",
            "                  tyre        227        229      0.786      0.747      0.818      0.436\n",
            "                   rov        130        130      0.879      0.727      0.875      0.336\n",
            "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2403.0Â±717.1 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.807      0.712      0.763      0.298\n",
            "                  cube        338        338      0.586      0.849      0.604      0.199\n",
            "                  ball        390        390      0.884      0.843      0.879      0.439\n",
            "              cylinder         93         93      0.774      0.828      0.853      0.319\n",
            "            human body        149        149      0.738      0.859      0.802      0.329\n",
            "                 plane        269        269      0.847        0.9      0.899      0.465\n",
            "           circle cage        197        197      0.809      0.239      0.554      0.206\n",
            "           square cage        335        335      0.799       0.51      0.613      0.183\n",
            "          metal bucket         11         11      0.959      0.727      0.823      0.214\n",
            "                  tyre        241        241      0.799      0.784      0.825      0.354\n",
            "                   rov        300        300       0.87      0.582      0.771      0.271\n",
            "Speed: 0.5ms preprocess, 7.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7626\n",
            "\n",
            " Epoha 12/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2451.0Â±292.8 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 599.6Â±77.6 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G      1.132      0.605     0.9268         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:48<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.884      0.846      0.895      0.433\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.881      0.851      0.896      0.434\n",
            "                  cube        525        526      0.922       0.88      0.927      0.446\n",
            "                  ball        605        606      0.935      0.872      0.946      0.483\n",
            "              cylinder        113        113      0.804      0.726      0.784      0.363\n",
            "            human body        278        279      0.905      0.864       0.92      0.437\n",
            "                 plane        167        167      0.892       0.94      0.942      0.478\n",
            "           circle cage        141        142      0.894      0.656       0.82      0.402\n",
            "           square cage        188        188       0.93      0.915      0.938      0.432\n",
            "          metal bucket         97         97      0.941      0.981      0.989      0.503\n",
            "                  tyre        227        229      0.767      0.852      0.842      0.435\n",
            "                   rov        130        130      0.825      0.823      0.849      0.358\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2361.0Â±596.8 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.778      0.695      0.723      0.272\n",
            "                  cube        338        338      0.579      0.746      0.556      0.162\n",
            "                  ball        390        390      0.872      0.867      0.841      0.404\n",
            "              cylinder         93         93      0.868      0.704      0.811      0.252\n",
            "            human body        149        149      0.773      0.798       0.78       0.32\n",
            "                 plane        269        269       0.86      0.918      0.919      0.477\n",
            "           circle cage        197        197      0.849      0.313      0.524      0.189\n",
            "           square cage        335        335      0.633      0.417       0.45      0.114\n",
            "          metal bucket         11         11      0.718      0.727      0.728      0.176\n",
            "                  tyre        241        241      0.765      0.702      0.774      0.303\n",
            "                   rov        300        300      0.863      0.754      0.851      0.324\n",
            "Speed: 0.5ms preprocess, 6.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7233\n",
            "\n",
            " Epoha 13/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2345.8Â±229.3 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 521.2Â±264.3 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.93G       1.09     0.5793      0.915         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:51<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.851      0.776      0.867      0.389\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.852      0.776      0.868      0.389\n",
            "                  cube        525        526      0.857      0.875      0.898      0.431\n",
            "                  ball        605        606      0.943      0.798      0.928      0.431\n",
            "              cylinder        113        113      0.891       0.58      0.808      0.356\n",
            "            human body        278        279      0.861      0.731      0.843      0.351\n",
            "                 plane        167        167      0.806      0.922      0.922      0.454\n",
            "           circle cage        141        142      0.875      0.641      0.769      0.333\n",
            "           square cage        188        188      0.901      0.904      0.947      0.404\n",
            "          metal bucket         97         97      0.927      0.825      0.939      0.426\n",
            "                  tyre        227        229      0.574      0.782      0.783      0.398\n",
            "                   rov        130        130      0.884      0.704      0.839      0.305\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2288.8Â±584.5 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.677      0.619      0.651      0.226\n",
            "                  cube        338        338      0.465      0.734      0.433      0.121\n",
            "                  ball        390        390      0.887      0.849      0.866       0.39\n",
            "              cylinder         93         93      0.839      0.447      0.701      0.197\n",
            "            human body        149        149      0.637      0.671      0.683      0.241\n",
            "                 plane        269        269      0.743      0.892      0.854      0.429\n",
            "           circle cage        197        197      0.752      0.262       0.52      0.157\n",
            "           square cage        335        335      0.495      0.433      0.386     0.0915\n",
            "          metal bucket         11         11      0.575      0.455      0.505     0.0861\n",
            "                  tyre        241        241      0.536      0.813      0.774      0.261\n",
            "                   rov        300        300      0.845      0.636      0.792      0.286\n",
            "Speed: 0.6ms preprocess, 6.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.6514\n",
            "\n",
            " Epoha 14/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2595.3Â±181.8 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 645.3Â±305.1 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.94G      1.079     0.5716     0.9111         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:48<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:20<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477       0.88      0.829      0.892       0.43\n",
            "\n",
            "1 epochs completed in 0.053 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:20<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477       0.88      0.828      0.892       0.43\n",
            "                  cube        525        526      0.927      0.901      0.938      0.475\n",
            "                  ball        605        606      0.949      0.859      0.939      0.465\n",
            "              cylinder        113        113      0.723       0.77       0.77      0.336\n",
            "            human body        278        279      0.927      0.864      0.922      0.436\n",
            "                 plane        167        167      0.939       0.91      0.967      0.515\n",
            "           circle cage        141        142      0.848      0.739      0.821      0.407\n",
            "           square cage        188        188      0.972      0.793      0.937      0.422\n",
            "          metal bucket         97         97      0.918      0.923      0.945      0.455\n",
            "                  tyre        227        229      0.816      0.738      0.831      0.446\n",
            "                   rov        130        130      0.779      0.787      0.848      0.341\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2559.4Â±914.5 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:24<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.785       0.74      0.774      0.292\n",
            "                  cube        338        338      0.586       0.84      0.562      0.174\n",
            "                  ball        390        390      0.865      0.867      0.865      0.411\n",
            "              cylinder         93         93      0.907      0.838      0.892      0.306\n",
            "            human body        149        149      0.812      0.785      0.829      0.328\n",
            "                 plane        269        269      0.886      0.881      0.913       0.51\n",
            "           circle cage        197        197      0.711      0.387      0.589      0.196\n",
            "           square cage        335        335      0.762      0.402      0.536      0.148\n",
            "          metal bucket         11         11      0.703      0.909       0.89      0.214\n",
            "                  tyre        241        241      0.787      0.763      0.833       0.33\n",
            "                   rov        300        300      0.835      0.723      0.834      0.305\n",
            "Speed: 0.5ms preprocess, 7.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7743\n",
            "\n",
            " Epoha 15/15\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_dataset/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=custom_loop, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/custom_loop, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 70/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2650.2Â±269.8 MB/s, size: 249.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/train.cache... 6070 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6070/6070 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 998.9Â±841.5 MB/s, size: 311.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_BASE/labels/val.cache... 1519 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1519/1519 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/custom_loop/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/1      1.92G      1.039     0.5543     0.9026         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 759/759 [02:48<00:00,  4.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:19<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.861      0.851      0.895      0.439\n",
            "\n",
            "1 epochs completed in 0.054 hours.\n",
            "Optimizer stripped from runs/custom_loop/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/custom_loop/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/custom_loop/weights/best.pt...\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95/95 [00:18<00:00,  5.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1519       2477      0.862       0.85      0.895      0.439\n",
            "                  cube        525        526      0.894       0.89      0.926      0.474\n",
            "                  ball        605        606      0.886      0.941      0.938      0.457\n",
            "              cylinder        113        113      0.741      0.814      0.812      0.359\n",
            "            human body        278        279      0.913      0.925      0.956      0.476\n",
            "                 plane        167        167      0.945      0.922       0.97      0.543\n",
            "           circle cage        141        142      0.855      0.667      0.804      0.417\n",
            "           square cage        188        188      0.944      0.846       0.93      0.438\n",
            "          metal bucket         97         97      0.907      0.887      0.961       0.46\n",
            "                  tyre        227        229      0.799      0.746      0.809      0.427\n",
            "                   rov        130        130      0.736      0.862      0.844      0.342\n",
            "Speed: 0.2ms preprocess, 3.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "Ultralytics 8.3.127 ğŸš€ Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2430.0Â±659.6 MB/s, size: 223.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/UATD_YOLO_Dataset_Test_v2/labels/test_set1.cache... 1596 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1596/1596 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:23<00:00,  8.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1596       2323      0.794      0.714      0.746      0.281\n",
            "                  cube        338        338      0.564      0.796      0.552      0.179\n",
            "                  ball        390        390      0.685      0.887      0.791      0.363\n",
            "              cylinder         93         93      0.866      0.837        0.9      0.291\n",
            "            human body        149        149      0.733      0.859      0.792       0.32\n",
            "                 plane        269        269      0.919      0.866      0.929      0.518\n",
            "           circle cage        197        197      0.838      0.341      0.589       0.22\n",
            "           square cage        335        335      0.763      0.484      0.564      0.158\n",
            "          metal bucket         11         11      0.975      0.636      0.766      0.176\n",
            "                  tyre        241        241      0.783      0.664      0.762      0.303\n",
            "                   rov        300        300      0.817      0.773      0.814      0.285\n",
            "Speed: 0.3ms preprocess, 7.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/custom_loop\u001b[0m\n",
            "mAP@0.5 test: 0.7458\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdmxJREFUeJzt3Xd8U9X7B/BPkrZJ9x5paWnZtOwpAqKsIsgXVJQhMpwgKIoDUREqigKK/pSlCAgi4kIZImUIqMiQTWnZHUB3C21p6UrO74+SQOigI8lNms/79er3a29ubp5zm5Kn5zznHJkQQoCIiIjIhsilDoCIiIjI3JgAERERkc1hAkREREQ2hwkQERER2RwmQERERGRzmAARERGRzWECRERERDaHCRARERHZHCZAREREZHOYABERVeH+++9Hq1atpA6jxqw1bnOYNWsWZDIZMjMzpQ6FJMQEiGxSXFwcZDIZVCoVrl27VuE5999/P2Qymf7Ly8sLnTt3xooVK6DVau/6GlqtFvn5+dWOaePGjejQoQNUKhVCQkIwc+ZMlJaW3vV5CQkJBnHe/rVu3bpqv76prV27Fp999plJXyM5ORmzZs3CsWPHTPo6RGT9mACRTVqzZg0CAgIAAD///HOl5zVo0ADffvstvv32W8yYMQOlpaV4+umn8dZbb1V4/tWrVzFr1iy0bt0aDg4OcHFxgZubGwYNGoTffvut0tf5448/MHToUHh4eOCLL77A0KFD8f777+PFF1+sdptGjhypj1X31a1bt2o/39TMlQBFRUUxASKiu7KTOgAicxNCYO3atRg1ahTi4+Px3Xff4ZlnnqnwXHd3d4wePVr//fPPP4/mzZtj4cKFmD17Nuzt7fWP/fHHH3jiiSfg6OiIkSNHYsaMGXB2dkZKSgqio6Px+OOPo1+/fli3bh1cXV0NXue1115DmzZtsG3bNtjZlf1aurm5Yc6cOZgyZQpatGhx13Z16NDBIFai2tBqtSguLoZKpZI6FCKTYg8QWQ3duP3Zs2cxevRouLu7w9fXFzNmzIAQApcuXcKQIUPg5uaGgIAAfPLJJxVeZ+/evUhISMCIESMwYsQI/PXXX7h8+XK1YnBycsI999yD/Px8ZGRk6I9HR0dj8ODBGDduHC5cuICPP/4Yjz/+OAYNGoRnnnkGP/30E44fP47k5GQ89NBDKC4u1j83NjYWsbGxeO655/TJDwC88MILEEJU2UN1p/z8fINrV8e4cePg4uKCK1euYOjQoXBxcYGvry9ee+01aDQag3M//vhj3HvvvfD29oajoyM6duxYrfjuv/9+/P7770hMTNQPz4WGhuofLyoqwsyZM9GkSRMolUoEBwfjjTfeQFFRkcF1tm/fjh49esDDwwMuLi5o3ry5vjdu9+7d6Ny5MwBg/Pjx+tf55ptvKo0rLy8PL7/8MkJDQ6FUKuHn54d+/frhyJEjVbZn27ZtcHJywsiRI1FaWopx48YZtEdH9569nUwmw+TJk/Hdd9+hefPmUKlU6NixI/766y+D82pyzeq6M+4744mIiIBSqcTWrVsBAEePHsWDDz4INzc3uLi4oE+fPti/f3+59lT2lZCQUGU8165dw8svv4zg4GAolUo0adIEc+fONRhi1g3xfvzxx/j000/RsGFDODo6olevXoiJiSl3zT///BM9e/aEs7MzPDw8MGTIEMTFxVX6+uPGjYOHhwfc3d0xfvx4FBQUlDtvzZo16NixIxwdHeHl5YURI0bg0qVLVbaNrIAgshIzZ84UAES7du3EyJEjxeLFi8WgQYMEALFgwQLRvHlzMXHiRLF48WLRvXt3AUDs2bOn3HUmTJggGjduLIQQoqCgQLi4uIh58+aVO69Xr14iIiKi3PEOHToIhUIh8vPzhRBCXL16VXh7e4uZM2canJefny9KS0uFEELk5eWJ/Px8kZ2dLZo3by4++ugj/Xlr1qwRAMSBAwfKvVaDBg3EI488UuV9iY+PFwCEi4uLACBkMpno1KmTiI6OrvJ5OmPHjhUqlUpERESIp556SixZskQ8+uijAoBYvHhxuXheeOEFsXDhQrFgwQLRpUsXAUBs3ry5ytfYtm2baNeunfDx8RHffvut+Pbbb8Wvv/4qhBBCo9GI/v37CycnJ/Hyyy+LL7/8UkyePFnY2dmJIUOG6K8RExMjHBwcRKdOncT//d//iaVLl4rXXntN3HfffUIIIVJTU8V7770nAIjnnntO/zoXLlyoNK5Ro0YJBwcHMXXqVPH111+LuXPnisGDB4s1a9boz7nzfbBp0yahVCrFmDFj9D/fsWPHioYNG5a7vu49ezsAolWrVsLHx0e89957Yu7cuaJhw4bC0dFRnDx50uDnUt1rVqQ6ceviadmypfD19RVRUVFi0aJF4ujRoyImJkY4OzsLtVotZs+eLT766CMRFhYmlEql2L9/v/75uvt8+5euPRkZGZXGl5+fL9q0aSO8vb3FW2+9JZYuXSrGjBkjZDKZmDJliv483fu7devWIjQ0VMydO1dERUUJLy8v4evrK1JTU/Xnbt++XdjZ2YlmzZqJefPmiaioKOHj4yM8PT1FfHx8uXvYvn178cgjj4jFixeLZ555RgAQb7zxhkGc77//vpDJZGL48OFi8eLF+muGhoaKq1ev3vXnQJaLCRBZDd0/Ws8995z+WGlpqWjQoIGQyWQGScXVq1eFo6OjGDt2rME1iouLhbe3t3j77bf1x0aNGiXatm1b7vV69eolWrRoITIyMkRGRoaIi4sTL730kgAgBg8erD9v1qxZomPHjvoPldTUVNGnTx8BQKhUKjF16lQxZswYfYK0YcMGERQUpH/+/PnzBQCRlJRULobOnTuLe+65p8r7kpiYKPr37y+WLFkiNm7cKD777DMREhIi5HL5XRMTIco+aAGI9957z+B4+/btRceOHQ2OFRQUGHxfXFwsWrVqJXr37n3X1xk0aFCFH+jffvutkMvl4u+//zY4vnTpUgFA7N27VwghxKeffioAVPmh+t9//wkAYuXKlXeNRwgh3N3dxaRJk6o85/ZE4pdffhH29vbi2WefFRqNRn9OTRMgAOLQoUP6Y4mJiUKlUomHH364Vtesbdy6eORyuTh16pTB8aFDhwoHBweDBDI5OVm4urrqk86KzJs3TwAQq1evrjK+2bNnC2dnZ3H27FmD42+++aZQKBT63wddAuTo6CguX76sP+/AgQMCgHjllVf0x9q1ayf8/PxEVlaW/tjx48eFXC4XY8aM0R/T3cOnnnrK4LUffvhh4e3trf8+ISFBKBQK8cEHHxicd/LkSWFnZ1fuOFkXDoGR1bm9XkehUKBTp04QQuDpp5/WH/fw8EDz5s1x8eJFg+f+8ccfyMrKwsiRI/XHRo4ciePHj+PUqVPlXuv06dPw9fWFr68vWrZsiS+++AKDBg3CihUr9Of89NNPmDRpEhQKBQDgueeew9mzZ7Fs2TKsXr0aBw4cMBgmGjBgADIzM3Hu3DkAwI0bNwAASqWy3OurVCr945UJCQlBdHQ0JkyYgMGDB2PKlCk4evQofH198eqrr1b53NtNmDDB4PuePXuWu3+Ojo76/7569SpycnLQs2fPuw4ZVeWnn35Cy5Yt0aJFC2RmZuq/evfuDQDYtWsXgLKfKQBs2LChWrPwqsPDwwMHDhxAcnLyXc/9/vvvMXz4cDz//PP48ssvIZfX/p/Pbt26oWPHjvrvQ0JCMGTIEERHR5cbdqyr6sTdq1cvhIeH67/XaDTYtm0bhg4dikaNGumPq9VqjBo1Cv/88w9yc3PLXWfXrl2YPn06XnzxRTz55JNVxvXTTz+hZ8+e8PT0NPi59+3bFxqNptyQ4NChQxEUFKT/vkuXLujatSu2bNkCAEhJScGxY8cwbtw4eHl56c9r06YN+vXrpz/vdhW957OysvRtW79+PbRaLR5//HGDGAMCAtC0aVP9e5OsE4ugyeqEhIQYfO/u7g6VSgUfH59yx7OysgyOrVmzBmFhYVAqlTh//jwAoHHjxnBycsJ3332HOXPmGJwfGhqKZcuW6afMN23aFH5+fvrHi4qKcOrUKTzwwAMAgPT0dGzcuBF79uzBfffdBwDo37+/QcwODg7w9PRERkYGmjZtqk8q7qx3AYDCwkKDpKO6vLy8MH78eHz00Ue4fPkyGjRoUOX5KpUKvr6+Bsc8PT1x9epVg2ObN2/G+++/j2PHjhnEW9uaFAA4d+4c4uLiyr2+Tnp6OgBg+PDh+Prrr/HMM8/gzTffRJ8+ffDII49g2LBhtU5G5s2bh7FjxyI4OBgdO3bEwIEDMWbMGIMPfQCIj4/H6NGj8dhjj+GLL76o1WvdrmnTpuWONWvWDAUFBcjIyNDPUKyr6sYdFhZm8H1GRgYKCgrQvHnzcue2bNkSWq0Wly5dQkREhP745cuXMXz4cHTv3h0LFiy4a2znzp3DiRMn7vpz16nsnv34448AgMTERACoNObo6Gjk5+fD2dlZf/zOf0s8PT0BlCX3bm5uOHfuHIQQFb42AINJEGR9mACR1dH1tNztGFA240snNzcXmzZtQmFhYYX/oK1duxYffPCBwYe5s7Mz+vbtW2ksugQrMDAQAPRFn7piXKAsEbv9H+WioiKkp6fD29sbQNlf1UDZX7DBwcEG109JSUGXLl0qff2q6K6VnZ191wSosvt3u7///hv/+9//cN9992Hx4sVQq9Wwt7fHypUrsXbt2lrFCJTNOmrdunWlH5q6djg6OuKvv/7Crl278Pvvv2Pr1q344Ycf0Lt3b2zbtq1abbjT448/jp49e+LXX3/Ftm3bMH/+fMydOxfr16/Hgw8+qD9PrVZDrVZjy5YtOHToEDp16mRwncoSwLr05hjjmneLW6c2SfbtiouLMWzYMCiVSvz4448GxfyV0Wq16NevH954440KH2/WrFmdYqqOu/27odVqIZPJ8Mcff1R4rouLi0njI9NiAkQ2Y/369SgsLMSSJUvK9RadOXMG77zzDvbu3YsePXpU+5pubm4AgJycHPj6+ur/cr9w4YJ+Fd7S0lIkJSXpn7NixQoEBQXp/4Fv164dAODQoUMGyU5ycjIuX76M5557ruaNBfTDV5X9hV1Tv/zyC1QqFaKjow2G61auXFmt51f2gd64cWMcP34cffr0uWtPklwuR58+fdCnTx8sWLAAc+bMwdtvv41du3ahb9++teqJUqvVeOGFF/DCCy8gPT0dHTp0wAcffGCQAKlUKmzevBm9e/fGgAEDsGfPHoPeD09PzwoX1NT1StxJN/x5u7Nnz8LJyUn/86rpNStyt7gr4+vrCycnJ5w5c6bcY6dPn4ZcLjdI1l966SUcO3YMf/31F/z9/asVW+PGjXH9+vUq/8C4XWX3TDdTrmHDhgBQacw+Pj4GvT/VjVEIgbCwMLMkZGRerAEim7FmzRo0atQIEyZMwLBhwwy+XnvtNbi4uOC7776r0TVdXFzQoEEDHDhwAAD0QynPPvssDh06hHPnzuk/WDMzM7FgwQK8/PLLmDdvnv7DOiIiAi1atMBXX31l8Nf9kiVLIJPJMGzYMP2xnJwcnD59Gjk5Ofpjt0/H17ly5QpWrFiBNm3a6HuY6kqhUEAmkxnEmJCQUOUCj7dzdnY2iFvn8ccfx5UrV7Bs2bJyj924cUO/mnZ2dna5x3XJo244TvcBV9nq3rfTaDTl4vHz80NgYGCFw5Hu7u6Ijo7WT5W/cOGC/rHGjRsjJycHJ06c0B9LSUnBr7/+WuFr79u3z6Bu6tKlS9iwYQP69++v72mo6TUrU1XclVEoFOjfvz82bNhgMJU9LS0Na9euRY8ePfTJ/8qVK/Hll19i0aJFNeqtfPzxx7Fv3z5ER0eXe+zatWvlVkH/7bffcOXKFf33Bw8exIEDB/SJqlqtRrt27bBq1SqDn39MTAy2bduGgQMHVjs2nUceeQQKhQJRUVEGvclAWS/RnUPsZGUkLMAmqhHdzI07ZwGNHTtWODs7lzv/9lkwV65cEXK5XLz88suVXv/RRx8V3t7eori4uNzzqzJhwgSD6dpHjx4VarVaP9vngQceEMOGDRMARHBwsPj+++/LXWPTpk1CJpOJ3r17i6+++kq89NJLQi6Xi2effdbgvJUrV5ab5TRu3DjRs2dPMWvWLPHVV1+Jt956S3h7ewsHBwexa9euu8Zf2f27c7bRzp07BQDRs2dPsWTJEhEVFSX8/PxEmzZtqjUrSTc76JVXXhFr164VGzduFEKUTYMfOHCgkMlkYsSIEeKLL74Qn332mZgwYYLw8vIS//33nxBCiClTpoj27duLd955Ryxbtkx88MEHIigoSDRo0EBcu3ZNCFE2K83Dw0M0b95cfP311+L7778XFy9erDCeq1evCmdnZzF27FixYMEC8dVXX4nHH39cABCffPKJ/rw73weXL18WoaGhIjQ0VD8rKTMzUzg7O4tGjRqJzz77TMyZM0cEBweLDh06VHsavEqlEsePH9efV5NrVqQ6ceviqWgmnG4afFBQkPjggw/E3LlzRaNGjQymwWdkZAiVSiXCw8MrnA5//fr1SuPLz88XHTp0EHZ2duKZZ54RS5YsER9//LH+/aj7Pa9oGvx7770nvLy8hLe3t0hOTtZfUzcNvkWLFmL+/PnivffeE76+vsLT09PgfVDZvyW636/bp8x/+OGHAoC49957xbx588SSJUvEG2+8IZo2bSrmz59/158DWS4mQGQ16pIAffLJJwKA2LlzZ6XX/+abbwQAsWHDhnLPr8q5c+eEnZ2dfl0bIYS4ceOG2Lt3r35dl9OnT4u4uDih1Worvc6vv/4q2rVrJ5RKpWjQoIF455139MmYTkUJ0Nq1a8V9990nfH19hZ2dnfDx8REPP/ywOHz48F1jF6L6CZAQQixfvlw0bdpUKJVK0aJFC7Fy5cpqT8u+fv26GDVqlPDw8BAADKZ4FxcXi7lz54qIiAihVCqFp6en6Nixo4iKihI5OTlCiLIEbMiQISIwMFA4ODiIwMBAMXLkyHLTqDds2CDCw8OFnZ1dlVPii4qKxOuvvy7atm0rXF1dhbOzs2jbtm25tY8qeh+cP39eqNVq0bJlS/37cdu2baJVq1bCwcFBNG/eXKxZs6bSafCTJk0Sa9as0d/L9u3bV5isVveaFalu3JUlQEIIceTIEREZGSlcXFyEk5OTeOCBB8S///6rf1yXnFT2dXsiUZG8vDwxffp00aRJE+Hg4CB8fHzEvffeKz7++GP9e1/3GvPnzxeffPKJCA4OFkqlUvTs2dMgYdTZsWOH6N69u3B0dBRubm5i8ODBIjY21uCcmiRAQpQtI9CjRw/h7OwsnJ2dRYsWLcSkSZPEmTNnqmwfWTaZEHf06xFRjc2fPx9RUVH47rvvMGTIkArPiYmJgUwmq1YNBtVfMpkMkyZNwsKFC6UOxSokJCQgLCwM8+fPx2uvvSZ1OFSPsAaIyAhef/11vPrqq3j44YcxePBg/Pjjjzhz5gwSExOxY8cOPP/88+jYsSNWrVoldahERATOAiMymqioKPTt2xezZs3CqFGjDIqF27dvjzVr1uCxxx6TMEIiItJhAkRkRD179sTOnTtx7do1nD9/HkVFRQgLC9OvE0RERJaBNUBERERkc1gDRERERDaHCRARERHZHNYAVUCr1SI5ORmurq512uSRiIiIzEcIgby8PAQGBt51k2QmQBVITk4utyklERERWYdLly7ddRNoJkAVcHV1BVB2A3X73dQXJSUl2LZtG/r37w97e3upwzE7W28/wHvA9tt2+wHeg/rc/tzcXAQHB+s/x6vCBKgCumEvNze3epkAOTk5wc3Nrd698avD1tsP8B6w/bbdfoD3wBbaX53yFRZBExERkc1hAkREREQ2hwkQERER2RwmQERERGRzmAARERGRzWECRERERDaHCRARERHZHCZAREREZHOYABEREZHNYQJERERkIzRagQPx2TicKcOB+GxotELqkCTDrTCIiIhswNaYFERtikVKTiEABVafOwS1uwozB4djQCu11OGZHXuAiIiI6rmtMSmYuObIzeTnltScQkxccwRbY1Ikikw6TICIiIjqMY1WIGpTLCoa7NIdi9oUa3PDYUyAiIiI6rGD8dnlen5uJwCk5BTiYHy2+YKyAEyAiIiI6rH0vMqTn9qcV18wASIiIqrH/FxVRj2vvmACREREVI91CfOC2l0FWRXnqN1V6BLmZbaYLAETICIionpMIZdh5uDwKs/p1NATCnlVKVL9wwSIiIionhvQSo0loztAZW/4se/uaA8A2HQiBdtj06QITTJMgIiIiGzAgFZqBHs6AgB6B2qx5qlOODKjH8Z2awgAeOWHYziffl3KEM2KCRAREZENKCzR4GJmAQCgV4AWXcO8oJDL8M5D4egS5oXrRaV4bvUh5NwokThS82ACREREZAPOpuVBoxXwdLKHu8Ot4/YKORY/0QGB7ipczMzHy+uO2sSiiEyAiIiIbEBcSi4AoKXaFbI76p19XJT48slOUNrJsetMBj7dflaCCM2LCRAREZENiE2+mQAFuFb4eOsG7vjo0dYAgIW7zmPLyfq9PxgTICIiIhsQm1J1AgQAD7dvgGd6hAEAXvvpOE6n5polNikwASIiIrPRaAX2XcjChmNXsO9Clk3UmlgCrVYgLiUPQNkQWFXefLAFujfxRkGxBs+tPoxrBcXmCNHs7KQOgIiIbMPWmBREbYo12JhT7a7CzMHhGNBKLWFk9d/lqzdwvagUDnZyhPk443wV59op5Fg4sgP+t+gfJGUX4MXvj2LluM6wU9SvPpP61RoiIrJIW2NSMHHNkXK7kqfmFGLimiPYGlO/602kFpuSAwBo5u8C+2okMp7ODvjqyU5wtFfg73OZmB99xtQhmh0TICIiMimNViBqUywqGuzSHYvaFMvhMBPSFUCHq92q/ZyWajd8/FhbAMCXf13EhmNXTBKbVJgAERGRSR2Mzy7X83M7ASAlpxAH47PNF5SN0RVA1yQBAoBBbdR44f7GAIBpv5xAzJUco8cmFSZARERkUul5lSc/tTmPak5XAB0e6F7j577avznub+6LwhItnv/2MLKuFxk7PEkwASIiIpPyc1UZ9TyqmWsFxbhy7QYAoMVdZoBVRCGX4f9GtEeYjzOuXLuByWuPokSjNXaYZscEiIiITKpzqCcc7RWVPi5D2WywLmFe5gvKhuiGv4K9HOGmsq/VNdwd7fHVkx3h7KDAvotZmLMlzpghSoIJEBERmdQXf57HjRJNlefMHBwOhVxW5TlUO7UpgK5IU39XLBjeDgCwcm8Cfj58ua6hSYoJEBERmczaA0n4v53nAACjugRD7V5+mOvlvs24DpAJ6et/1DWv/7lTZEQApvRpCgB469eTOHbpWp2vKRUmQEREZBI7YtPwzm8nAQAv9W6COY+0wT/TeuP7Z+/B/41oh34t/QEAf8SkoLQe1JRYqtjbNkE1hil9mqJvS38Ul2ox4dvDVlu8zgSIiIiM7kjSVUz+/gi0Ani8UwO80q8ZgLKC2m6NvTGkXRDmDWsDd0d7nE7Nw/cHkySOuH4qLtXifLpuBljdhsB05HIZPh3eFo19nZGaW4gX1hxBcan1JbBMgIiIyKguZFzH09/8h8ISLR5o7osPHm4Nmax8fY+nswNe61+WGH287Syu5tfPPaekdC49DyUaATeVHYI8HI12XVeVPZaN6QRXlR0OJV5F1KZTRru2uTABIiIio0nPK8TYFQdxtaAEbRu4Y9ETHarcemFklxC0CHBFzo0SfLK9/m23ILVb6/+4VZiE1kUjXxd8PqI9ZDLguwNJWHvAunrxmAAREZFR5BWWYPzK/3D56g2Eejth+bjOcHKoes9tO4Ucs/4XAaCsYFo3Y4mMQ3c/W9ZxBlhlHmjhh9f6NwcAzNwYg8OJ1rOaNxMgIiKqs+JSLSauOYJTybnwdnbAqqe6wMdFWa3n3tPIG4PaqKEVwKxNpyAE9wQzFt0mqHWdAl+VF+5vjIGtA1CiEZiw5ghSq9j2xJIwASIiojrRagWm/XIC/5zPhJODAivHd0ZDb+caXeOtgS2hspfjYHw2Np/gzvDGIIS4tQaQkQqgKyKTyTB/WFu0CHBFRl4Rnl9zGIV3WffJEjABIiKiOpkXfQa/Hr0ChVyGxU90QJsGHjW+RpCHIyb2agIA+HBLHAqKS40cpe1JzilEbmEp7BUyNPUzzhT4yjgr7fDVk53g7miP45eu4d0NMRbfk8cEiIiIau2bvfFYuucCAOCjR1rj/uZ+tb7W870aIcjDEck5hVi6+4KxQrRZut6fxr4ucLAz/cd9iLcTFo5qD7kM+PHQZXy7P9Hkr1kXFpEALVq0CKGhoVCpVOjatSsOHjxY6bn3338/ZDJZua9Bgwbpzxk3bly5xwcMGGCOphAR2YwtJ1MQtTkWAPB6ZHM81im4TtdT2Ssw46GWAIClf13EpeyCOsdoy8wx/HWnnk19Mf3Bsp/he5tisf9iltleu6YkT4B++OEHTJ06FTNnzsSRI0fQtm1bREZGIj09vcLz169fj5SUFP1XTEwMFAoFHnvsMYPzBgwYYHDe999/b47mEBHZhAMXs/DyD8cgBPDkPQ3xwv2NjXLdyIgA3NvYG8WlWnzwu/VvuCklcxRAV+SZnmEY0i4QpVqBSd8d0e9Eb2kkT4AWLFiAZ599FuPHj0d4eDiWLl0KJycnrFixosLzvby8EBAQoP/avn07nJycyiVASqXS4DxPT09zNIeIqN47m5aHZ1cfQnGpFv3D/THrfxFGW2NGJpNh5uAIKOQybD2Vin/OZRrlurbo9jWAzEkmk+GjR9ogItANWfnFeP7bQxZZFF31Ag0mVlxcjMOHD2P69On6Y3K5HH379sW+ffuqdY3ly5djxIgRcHY2nHGwe/du+Pn5wdPTE71798b7778Pb2/vCq9RVFSEoqIi/fe5uWXdhiUlJSgpKalpsyyarj31rV3VZevtB3gP2P66tT8lpxBjlh9AbmEpOoR44JNhraDVlEJrxM+3Rt4qPNElGKv3J2HWxhhsnNStysUUa8oW3gN5hSVIujmE2NTHyaCt5mi/nQxYNLItHl6yHzFXcvHGT8fx8bBWRl+M8U41aZNMSFimnZycjKCgIPz777/o1q2b/vgbb7yBPXv24MCBA1U+/+DBg+jatSsOHDiALl266I+vW7cOTk5OCAsLw4ULF/DWW2/BxcUF+/btg0KhKHedWbNmISoqqtzxtWvXwsnJqQ4tJCKqPwpKgc9jFEi5IYO/o8CUCA2c7U33Wu8fVSC/VIZHQjXopbbsGUWW5kIu8PkpO3g4CER1lK735XwOsChWAS1kGNpQgwcCTftzLCgowKhRo5CTkwM3t6p7viTtAaqr5cuXo3Xr1gbJDwCMGDFC/9+tW7dGmzZt0LhxY+zevRt9+vQpd53p06dj6tSp+u9zc3MRHByM/v373/UGWpuSkhJs374d/fr1g729if7lsmC23n6A94Dtr137i0o0eGr1EaTcuAo/VyV+eK6LUfeWqkip+jJmbIzF9lQl3hjRA97ODka5ri28B1bvTwJOnUaHMD8MHNje4DFzt99zfxLe+/00NiYp8L9eHeBgJ0d6XhH8XJXo1NATCrnxeoV0IzjVIWkC5OPjA4VCgbS0NIPjaWlpCAgIqPK5+fn5WLduHd577727vk6jRo3g4+OD8+fPV5gAKZVKKJXlVyy1t7evt78c9blt1WHr7Qd4D9j+6rdfqxWY9uNJHEy4ClelHb4Z3wWhvqb/43DUPaFYd+gyTiXn4v/+vIAPH2lj1OvX5/fAmbTrAIBWQe6VttFc7R/foxHiUq/jp8OX8fS3R3D7uJPaXYWZg8MxoJXaKK9Vk/ZIWgTt4OCAjh07YufOnfpjWq0WO3fuNBgSq8hPP/2EoqIijB49+q6vc/nyZWRlZUGtNs4NJiKyFUIIvLc5Fr+fTIG9QoYvn+xotqJahVym3yds3X+XEHMlxyyvWx/oCqBNtQdYTchkMvRs6gMAuLPoJjWnEBPXHMHWGPOv/i35LLCpU6di2bJlWLVqFeLi4jBx4kTk5+dj/PjxAIAxY8YYFEnrLF++HEOHDi1X2Hz9+nW8/vrr2L9/PxISErBz504MGTIETZo0QWRkpFnaRERUXyz7+yK++TcBAPDJ4+1wbxMfs75+51AvDGkXCCGAWRu5T1h1lGi0OJMmzQywimi0Ah/+cbrCx3Q/zahNsdBozfuzlbwGaPjw4cjIyMC7776L1NRUtGvXDlu3boW/vz8AICkpCXK5YZ525swZ/PPPP9i2bVu56ykUCpw4cQKrVq3CtWvXEBgYiP79+2P27NkVDnMREVHFfjt6BXO2lH1wvTOoJf7XNlCSOKY/2BLbY9NwKPEqNh5PxpB2QZLEYS0uZuSjuFQLF6Udgj2ln8hzMD4bKVVskCpQNrvwYHw2ujWueLa2KUieAAHA5MmTMXny5Aof2717d7ljzZs3r/SvAEdHR0RHRxszPCIim/PPuUy8/vNxAMDTPcLwTM9GksUS4K7CpAeaYH70GczZEoe+Lf3hrLSIjy+LpFsAsaXaFXIjFhjXVnpe9XaHr+55xiL5EBjZDo1WYN+FLGw4dgX7LmSZvbuTiKrnVHIOJqw5jBKNwENt1Hh7YEupQ8LTPcIQ4uWEtNwiLNp1XupwLJol1f8AgJ+ryqjnGQtTaDKLrTEpiNoUa9ANauzq/7vRaAUOxGfjcKYM3vHZ6NbEz6jTL4nqg0vZBRi38j9cLyrFPY288MnjbS2iF6Fsn7BwPLv6EL7+Ox7DOwejobfz3Z9og/R7gFlIAtQlzAtqdxVScwpR0Z+9MpT18nUJ8zJrXOwBIpPbGpOCiWuOlBsDNmf1/9aYFPSY+ydGrziE1ecUGL3iEHrM/VOSmQdElupqfjHGrjyIjLwitAhwxVdjOkFpV37xWKn0bemHnk19UKzRYvZm7hNWESEEYlPMvwlqVRRyGWYODgdQluzcTvf9zMHhZv+DlAkQmZRGKxC1KbbCrF/c/HrntxjEJuciPjMfydduIPN6EfIKS1BUqjHKjA9LSMCILN2NYg2eXvUfLmbkI9BdhW/Gd4GbyrLWyCnbJywcdnIZdsSlYc/ZDKlDsjhpuUXIzi+GQi5DM39XqcPRG9BKjSWjOyDA3XCYK8BdhSWjO5htJOB2HAIjk7pb9T8AZF4vxsDP/670cQc7OZR2cijtFDf/X64/5nDzuMMdx3XH7BUyrNmfVGkCJkPZ9Mt+4QEcDiObVarR4sXvj+JI0jW4O9pj1VNdyn1QWYomfq4Ye28olv8Tj6hNp7B1yn1wsOPf8jpxN3t/Gvk4Q2VvOb13QFkS1C88AAfjs5GeVwg/17JhL6n+7WUCRCZV3ap+V6UCgAxFGi2KS7UGjxWXlh3LQ6nR49NNvxzx1T50CPFEiLcTGno5o6G3E9TuKtgZcQNGjVZYzC8+kY4QAu9uPIUdcWlwsJPj67Gd0NSCeg4qMqVvU2w4dgUXM/Kxel+CpDPULI2lDX/dSSGXmXWqe1WYAJFJVbeq/6sxnfW/FFqtQLFGi2KNFkUluv/X3PG9FsUajcH3RXecV1SqRVxKbrW6yf9LuIr/Eq4aHLOTyxDk6YgQLyc0vJkYhXiX/XeIlxOcHKr/62MJReBEFVn453msPZAEmQz4fEQ7dA41byFqbbip7PFGZAu88csJ/N+OcxjSLgi+rlznDbC8AmhLxgSITEpX/V/ZMFhF1f9yuQwquaKs+7aOvfD7LmRVKwEa260hZDIZkrILkJiVj0tXb6C4VIvErAIkZhXg73Pln+PjoryZGDndlhiV9R55OztAJivr3dHVIN05DKerQZJq/Jtsz50zIS9fK8In288CAKL+F2FV78NhHRtgzYFEnLicg/nRpzFvWFupQ7IIlt4DZEmYAJFJKeQyvNqvGV77+US5x8xR/V/d6ZfvDo4wiEGrFUjLK0RiVgGSsgqQmJ1f9t/ZZQlRzo0SZF4vQub1IhxOvFruus4OCgR7OSHEyxF7z2exBokkZ9gLqcDqc4f0j71wf2OM6RYqWWy1IZfLMHNwBB5d8i9+PHQZo7o2RLtgD6nDklR+USkSsvIBWM4aQJaMCRCZXFJ2AYCyIaXS2xY/DDDDEJBu+uXENUcgAwwSkaoSMLlcBrW7I9TujrinUfnx6pyCkrJkSJcY3UySkrIKkJJbiPxiDU6n5uF0al6V8Um1BDzZlsp6IXVaB7mbNR5j6djQE490CML6I1cwa+MprJ94r0WsWSSV06l5EALwc1XCx4VDgnfDBIhMKrewBCtvbqT4f8PbwctFafYiYN30yztrcOqSgLk72aO1kztaNyj/wVFYosHlqzeQlJ2P30+k4JcjV+56PXMvAU+2o6qlKICyPwTe2xyL/hHW2Qv55oAWiI5JxbFL1/Dr0St4tGMDqUOSDIe/aoYJEJnUqr0JyCssRTN/FzzYWi3ZX2e66Zf7zqdj298H0L9nV5OtBK2yV6CJnwua+LnA0d6uWgmQuZeAJ9thqRtRGoufmwov9mmKj/44jY+2nkb/CH+4Wtj6RebCAuia4eIJZDLXi0qxfG88AGDSA00k75pWyGXoGuaFjj4CXc3U+6SrQarqldQSLAFPtsNSN6I0pvHdQxHm44yMvCIs/NN29wnTrQHE+p/qYQJEJrNmfyKuFZQgzMcZD7UJlDocSVS1BLzO9AdbWOXQA1kHS92I0piUdgrMeKhsw9YVe+NxMeO6xBGZn0YrcDqVQ2A1wQSITOJGsQZf/30RQNkME1v+gK9sCXjdLTmXbnv/WJP5dAnzgpuq8moHGepHL2TvFv54oLkvSjQCszfHSh2O2cVn5qOwRAtHewVCuUlstbAGiEzi+4NJyLxejAaejhjaPkjqcCRX0RLwWdeLMPn7o1iy+wIGtVGjRQD/aiPj++tsBvIKK15FXcqNKE1hxkPh+Of8X9h1JgN/nk5D7xb+UodkNroC6BZq13rxszQH9gCR0RWWaPDlXxcAAC/c3wT2RtxOwprploAf0i4I3Rp7Y1AbNfqH+6NUKzDtl5PQaOu+8SvR7c6k5uHF749CAOje2NuiNqI0hUa+LniqexgAYPbmOBSVaiSOyHxY/1Nz7AEio/vp8GWk5RZB7a7Cox3Z+1MZmUyG2UNbYd/FLBy/dA0r98ZzTyMymszrRXjqm/9wvagU9zTywsrxXaCQy8wyE1JKk3s3wfqjVxCfmY+VexMwoVdjqUMyC84Aqzn+aU5GVaLRYunust6f5+9rBKWdZe1GbGn83VR4a2BZ8eYn287i0s1FI4nqorBEg+e/PYwr124g1NsJS0d3hIOdXJKZkObmqrLHmwNaAAC+2HkO6bnWO7utJrgGUM0xASKj+vXIFVy5dgM+LkqM6BIidThWYXinYHQN88KNEg3e+vUkhOBQGNWeEALT15/E4cSrcFPZYfm4zvBwcpA6LLN6uH0Q2gV7IL9Yg4+2npY6HJPLyCtCRl4RZDKgRYCr1OFYDSZAZDSlGi0W7S5bg+P5+xqVbWZKdyWXy/DRo22gtJPj73OZ1Vo4kagyi3dfwK9Hr0Ahl2HxEx3R2NdF6pDMTi6XIep/EQCA9UeuVLhfX32iq/8J83aGkwMrW6qLCRAZzaYTyUjMKoCXswOeuIe9PzUR5uOMl/s2AwDM3hyLjLwiiSMia7TlZArmR58BULa7e4+mPhJHJJ22wR54vFPZthhRm05BW48nGeiGv1py+KtGmACRUWi0Qr8C69M9wvhXSC080zMM4Wo35NwoQdSmU1KHQ1bmxOVrmPrjMQBlKyOPvqehtAFZgNcjW8BVaYcTl3Pw8+HLUodjMiyArh0mQGQUW2NScSEjH24qO4zpxn94a8NeIce8YW2gkMuw+UQKdsSmSR0SWYnUnEI8u/oQCku0uL+5L94ZFC51SBbB11WJKX2bAgDmRZ9GbmGJxBGZBguga4cJENWZVivwxZ/nAADju4fZ7EaExtAqyB3P9Cxbx+Sd32Lq7T/YZDwFxaV4ZvV/SMstQjN/F3wxsn29nN1VW2O6haKxrzMyrxfj8x3npA7H6ApLNPqtPyLYA1QjTICoznbEpeF0ah5clHb6Rcio9l7u0wwNvZ2QmluIuX/U/xksVHtarcDUH44j5kouvJwdsHxsZ/4BcgcHOzneHVxWEP3Nvwk4n54ncUTGdSY1D1oBeDs7wNdVKXU4VoUJENWJEAJf3Kz9GdOtIdyd+I9vXTk6KPDhI60BAN8dSMLB+GyJIyJL9fG2M9h6KhUOCjm+erIjgr2cpA7JIvVq5ou+LctWXZ+18RT2X8zC4UwZDsRnW/0K7LcPf8lk7PmrCSZAVCd7zmbg5JUcONor8HQP9v4Yy72NfTCiczAA4M1fTqCwxHaW9Kfq+eXwZSy+uejo3GGt0SnUujczNbUZD7WEnVyGf85n4cmVh7H6nAKjVxxCj7l/YmtMitTh1RoLoGuPCRDV2u29P090DYG3C7tfjWn6wJbwdVXiYma+vsaKCAD+S8jG9PUnAQCTHmiMh9s3kDgiyxeXkovSCnp7UnMKMXHNEatNguJYAF1rTICo1vZdyMLhxKtwsJPjufu4h5WxuTvaY/aQstqFL/dc1P+lR7btUnYBnv/2MIo1WjzYKgCv9msudUgWT6MViNoUW+FjupQoalOs1Q2HabWCm6DWARMgqrXPb/ZKjOwcDD831V3OptoY0EqNAREBKNUKvLn+BEo1WqlDIgnlFpbgqW/+Q3Z+MVoFueGTx9tCzhlfd3UwPhspOZXvCSYApOQUWl29XVJ2AfKLNXCwk6ORj7PU4VgdJkBUK/8lZGP/xWzYK2R43kZ2W5bKe0Mi4KoqW8xt5d4EqcMhiZRqtHhx7VGcS78Ofzclvh7TmQuOVlN6XvU2RK3ueZZCVwDdIsAVdgp+nNcU7xjViq72Z1jHBgj0cJQ4mvrNz02Ft3U7xm8/g8SsfIkjIim8/3sc9pzNgMpejq/HdEaAO3tdq8vPtXr3qrrnWQp9/Q+Hv2qFCRDV2LFL1/DX2Qwo5DJM7NVE6nBswvDOwejWyBuFJVruGG+D1uxPxDf/JgAAPhveDq0buEsbkJXpEuYFtbsKlQ0WygCo3VXoEmZdM+l0dYGs/6kdJkBUYwtv1v4MbReEEG+uO2IOMpkMHz7SGko7Ofaez8JP9XhfIzL0z7lMzNxYtjfc65HNMaCVWuKIrI9CLsPMwWXbg1SWBM0cHG51K2hzC4y6YQJENXIqOQc74tIhk5VNvyXzCfVxxiv9ynaMf39zrNXVK1DNnU+/jonfHYZGK/BI+yC8cD9/52prQCs1lozuUG7o0FmpwJLRHawusbyaX6wv7G4R4CpxNNaJCRDVyKJdZbU/D7UJRCNfF4mjsT3P9AhDqyA35BaWImpjxdN6qX64ml+Mp1f9h7zCUnRq6IkPH23NlX7raEArNf6Z1htrnuqEXgFlMyq9nR0QGREgcWQ1p6v/aejtxO1PaokJEFXbubQ8/BGTCgCY/ABrf6Rgp5Bj7qNlO8b/fjIF206lSh0SmUBxqRYT1hxGYlYBGng64ssnO0Jpp5A6rHpBIZeha5gXBoVoobSTIyn7Bk6nWt/+YLrhr5YBHP6qLSZAVG0Ld52HEMCAiAA0Z5erZCIC3fULT87YwB3j6xshBGb8FoMD8dlwUdphxbjOXGXdBJQKoEcTbwBAtBX+IaHfAoP1P7XGBIiqJT4zH5uOJwMAJvdm74/UpvRpijAfZ6TlFuHDLdwxvj75+u94/HDoEuQy4ItR7dHMn39smEr/cD8AwNYYK0yAOAW+zpgAUbUs2nUeWgH0buGHVkGcgis1lf2tHeO/P5iE/RezJI6IjGFHbBrm/BEHAJjxUDgeaO4ncUT1W+/mflDIZTidmmdV62sVlWpwPv06APYA1QUTILqrS9kF+PXoFQDAi+z9sRj3NPLGyC4hAIDp609yx3grF5uci5fWHYUQZZsLj7s3VOqQ6j0PJ3vc06hs7R9rGgY7l3YdpVoBd0d7qLkgZq0xAaK7WrLnAjRagZ5NfdA+xFPqcOg2bz7YAn6uSsRn5uP/dnLHeGuVnleIZ1b9h4JiDbo38cas/0VwxpeZDLg5A8yahsFuH/7i+6T2mABRlVJybuDnQ2WL7r3Yu6nE0dCd3B3tMXtoKwDAV39dxKnkHIkjopoqLNHgudWHkZxTiEY+zlg8qiPsua+T2fQLL0uAjiRdQ3qudaytxQJo4+BvGVXpyz0XUazRomuYl9UtE28rIiMCMLB1ADRagWm/cMd4ayKEwBs/n8CxS9fg7miP5eM6w92Ja7qYU4C7Cu1DPAAA0bFp0gZTTdwDzDiYAFGl0vMK8f3BJADs/bF0s/4XATeVHWKu5GL5P/FSh0OV0GgF9l3IwoZjV7DvQhY+23EOG48nw04uw9LRHRHm4yx1iDZJtxCiNayrJYS4tQYQE6A6sZM6ALJcX/8dj6JSLdqHeKD7zfUyyDL5uarwzqBwvPHLCSzYfhaREQEI5YepRdkak4KoTbH67Qtu98HDrdCtMX/HpBIZEYCP/jiNfReycK2gGB5ODlKHVKnLV28gr7AU9goZmvhxNf66YA8QVSg7vxhr9icCAF7q3ZSFdlbgsU4N0L2JN4pKtZi+njvGW5KtMSmYuOZIhckPUFbLRdIJ83FGiwBXlGoFdsalSx1OlXS9P039XOFgx4/wuuDdowot/+ciCoo1aBXkhvub+0odDlWDTCbDnIdbQ2Uvx76LWfjx0CWpQyKUDXtFbYpFZemoDEDUplhotExYpdT/5jCYpU+Hj+MO8EbDBIjKySkowap/y3p/Jj/A3h9r0tDbGVN1O8b/Hmc1s1rqs4Px2ZX2/ACAAJCSU4iD8dnmC4rK0U2H33M2AwXFpRJHUzndDDDW/9QdEyAq55t/E3C9qBTN/V3RP9xf6nCohp7qHobWQe7IKyzFzI2npA7H5qXnVS8Jre55ZBot1a4I9nJEUakWf53NkDqcSnELDONhAkQG8gpLsGJv2Syiyb2bQC5n74+1uX3H+D9iUq1qgbf6yKOa09r9XLmir5RkMpnFL4qYc6MEl6/eAMAEyBiYAJGBb/cnIudGCRr5OmNga7XU4VAthQe64fmbO8a/uyEGOTe4Y7wUkrIKMPePqjerlQFQu6u4zpYF0E2H33k6HcWllree1umbvT9BHo5cL8oImACRXkFxKb7+u6z3Z9L9TaBg749Ve6lPUzTycUZ6XhE+3BIndTg2Z0dsGh764m/EpuTBRVm24sidv1G672cODufvmwXoEOIJX1cl8gpLsc8CNxjm+j/GxQSI9NYeSEJ2fjFCvJwwpF2g1OFQHd2+Y/y6/y7h3wuZEkdkGzRagfnRp/HM6kPILSxF+xAPbJ96H5aO7oCAOzauDHBXYcnoDhjQir2tlkAul+nrHi1xGIxbYBgXF0IkAGX7EX3110UAwAv3N4Yd9yKqF7o28sYTXUPw3YEkvLX+JH5/qSeOJmbjcKYM3vHZ6NbEjz0PRpR5vQhT1h3F3vNlvQfj7g3FWwNbwsFODrW7I/qFB+BgfDbS8wrh51o27MX7b1kiIwLw3YEkbI9Nw/tDW1nUz4cF0MbFBIgAAD8euoT0vCIEeTjikQ4NpA6HjGjagy2wIy4NCVkF6PLBDuQXawAosPrcIajdVZg5OJw9EEZwODEbk747itTcQjg5KPDRo23wv7aGPakKuYwrPlu4exp5w01lh8zrRTiSdBWdQy2jNqtEo8W5tOsAgAj2ABkF/8wnFJdqsXT3BQDAhF6NuLpoPeOmsscj7cuS2rLk55bUnEJMXHMEW2NSpAitXhBCYOXeeAz/cj9ScwvR2NcZGyZ1L5f8kHVwsJOjT8uyYbBoCxoGu5BxHcUaLVyVdmjg6Sh1OPUCP+kIvxy5jOScQvi5KvFYp2CpwyEj02gFfjt2pcLHdGsPcyXi2skvKsWL3x9F1KZYlGoFBrVRY8PkHmjq7yp1aFQHutlgW0+lWsyWMrcvgMjFaY3DIhKgRYsWITQ0FCqVCl27dsXBgwcrPff++++HTCYr9zVo0CD9OUIIvPvuu1Cr1XB0dETfvn1x7tw5czTF6pRqtFi8+zwA4Ln7GkFlr5A4IjI2rkRsGufT8zBk0V5sPpECO7kM7z4UjoUj2+tnfJH16tXMFyp7OS5fvaGvu5EaC6CNT/IE6IcffsDUqVMxc+ZMHDlyBG3btkVkZCTS0yvekG79+vVISUnRf8XExEChUOCxxx7TnzNv3jx8/vnnWLp0KQ4cOABnZ2dERkaisJArrd5pw7FkXMq+AW9nBzzRtaHU4ZAJcCVi49t0PBn/W7gX59Ovw99NiR+evwdP9QjjX+b1hKODAr2ale2BaCnDYCyANj7JE6AFCxbg2Wefxfjx4xEeHo6lS5fCyckJK1asqPB8Ly8vBAQE6L+2b98OJycnfQIkhMBnn32Gd955B0OGDEGbNm2wevVqJCcn47fffjNjyyyfRiuwaFdZ788zPRvB0YG9P/VRdVcY5krEd1dcqsWsjafw4vdHUVCsQbdG3vj9pZ7o2NAyCmXJeAa0ujUMJjUhhH4TVK4BZDyS9tUWFxfj8OHDmD59uv6YXC5H3759sW/fvmpdY/ny5RgxYgScnZ0BAPHx8UhNTUXfvn3157i7u6Nr167Yt28fRowYUe4aRUVFKCoq0n+fm1v2RispKUFJSf1aQVfXnpKSEkSfSMHFzHy4O9phRKfAetfWitzeflvRvoErAtyUSMstqnRHcndHO7Rv4GoT96W274GUnEJM+eE4jl7KAQBMuC8MU3qXLRlhTffNFn8H7lSde9CzsRfs5DKcTbuOsynXEObjbK7wyknJKcTVghIo5DKEeSnr/LOrz++BmrRJ0gQoMzMTGo0G/v6GG276+/vj9Omql48HgIMHDyImJgbLly/XH0tNTdVf485r6h6704cffoioqKhyx7dt2wYnJ6e7xmGNordtx7zjCgAy3OtdhL92bpM6JLPavn271CGY1cAAGVbk6jp8bx+mEQBkyLlRinGLojEsTAt7yfuFzaMm74EzOTKsPivH9VIZHBUCo5to0bLkHLZFW29toa39DlTkbvegiascp3Pk+OLXv9A3SLpi6JirMgAK+Cm12Lk92mjXrY/vgYKCgmqfa9XVesuXL0fr1q3RpUuXOl1n+vTpmDp1qv773NxcBAcHo3///nBzq1/djSUlJdi+fTsUIe2Qsj8GLko7vD/mAbg52sa+Mrr29+vXD/b2ttFmABgIoMOpNLy/5TRSc2/1dga4qdAl1BObT6Zif7oc1+08sHBkWwR51N9ptjV5D2i1Al/9HY+l+89DK4CWAa74YmRbNPSy3j+MbPV34HbVvQfXfC5h5qY4JGm9MHBgVzNGaCh+90Xg9Hl0aRaIgQNb1/l69fk9oBvBqQ5JEyAfHx8oFAqkpaUZHE9LS0NAQECVz83Pz8e6devw3nvvGRzXPS8tLQ1q9a3F3dLS0tCuXbsKr6VUKqFUKssdt7e3r3dvDgAQAvjy70QAZSvVertZ7z/mtVVff7ZVeahdAzzYJgj7zqdj298H0L9nV/1K0I+dy8BL3x9FTHIuHl6yH5+PbI+eTX2lDtmk7vYeyCkowdQfj2Pn6bIJGY91bIDZQ1vVm5mStvg7cKe73YMHWwdi1uY4HL+cg6wCTbmtTMzlbPrNBRCD3I36M6uP74GatEfSzm4HBwd07NgRO3fu1B/TarXYuXMnunXrVuVzf/rpJxQVFWH06NEGx8PCwhAQEGBwzdzcXBw4cOCu16zvNFqBA/HZ2JgkR2xKHhzt5XiqR5jUYZEZKeQydA3zQkcfga63bcPQs6kvNr3YA62D3HG1oARjVxzEol3nobXRtYFiruTgoYV/Y+fpdDjYyTH30daY/1jbepP8UPX4uanQIcQTALAtVrpiaP0UeLW7ZDHUR5KP9k+dOhXLli3DqlWrEBcXh4kTJyI/Px/jx48HAIwZM8agSFpn+fLlGDp0KLy9DZeVl8lkePnll/H+++9j48aNOHnyJMaMGYPAwEAMHTrUHE2ySFtjUtBj7p8YveIQ/kwu+7HLZTIcjLe8HY9JGg08nfDThG4Y3ikYWgHMjz6D59ccRm5h/SuUrMqP/13CI0v+xaXsGwj2csT6ifdieOcQqcMiiQzQLYoo0XT460WlSMgqq2tpqeYCm8YkeQ3Q8OHDkZGRgXfffRepqalo164dtm7dqi9iTkpKglxumKedOXMG//zzD7Ztq7hw94033kB+fj6ee+45XLt2DT169MDWrVuhUtnmNN+tMSmYuOZIuRlA+cUaTFxzhLtRk57KXoG5w9qgXYgHZm44he2xaRiycC+Wju6I5gH1+x/fwhIN3t0Qgx8PXQYA9G7hh08fbwd3p/o1REA1ExkRgA+2xOFAfDau5hfD09nBrK9/+ub09wA3FbxdypdqUO1JngABwOTJkzF58uQKH9u9e3e5Y82bN69yeXKZTIb33nuvXH2QLdJoBaI2xVY6/Rko2wahX3iARe16TNIa2SUE4Wo3TFxzGPGZ+Ri6aC/mDWuDwfV0f6ukrAJMWHMYsSm5kMuAV/s3x8RejSHn74TNC/F2Qku1G+JScrEjLs3s2wXdWv+nfv8BIgXJh8DItLgNAtVW22APbHqxB7o38caNEg1e/P4oZm+ORYlGK3VotaargzucKcOB+GxotAI7YtPw0Bd/IzYlF17ODlj9VFdMeqAJkx/S0w2DRUuwKKJ+BWhugWF0FtEDRKbDbRCoLrxdlFg1vgs+2X4WS3ZfwPJ/4nHySg4WjmpvdStHb41JQdSm2Jt/ECiw+twhOCsVyC/SAADah3hg8RMdoHavv0sAUO1EtvLHpzvO4q9zmcgvKoWzGfd7YwG06bAHqJ7jNghUV3YKOaYNaIGlozvCRWmHg/HZGPzFPzicaD29hro6uDt7Q3XJzwPNffHDc92Y/FCFmvu7ItTbCcWlWuw+k2G21y3VaHE6NQ8Ae4BMgQlQPdclzAtqdxUq68yXAVC7q9AljHsZUdUGtArAhsnd0dTPBWm5RRj+5X6s+jehyno8S1CdOrjTqXmsgaNKyWQyREowDJaQlY+iUi2cHBRWvfimpWICVM8p5DLMHBxe4WO6f+5nDg7nP/5ULY19XfDbpO4Y1FqNUq3AzI2nMPXH47hRrJE6tEoduJhVZR0cwDo4urvIm5uj/nk6HUWl5nm/n7o5/NUiwJU1aSbABMgGDGilxuInOpTrBQpwV3EKPNWYs9IOC0e1xzuDWkIhl+HXo1fw8OK9SMzKlzo0Pa1W4L+EbMzaeAoTvztSreewDo6q0q6BB/zdlLheVIp/L5hn/TQWQJsWi6BtRMdQz5vbXgKjGmvwYK9b2yAQ1ZRMJsMzPRshItAdL35/BKdT8zD4i3/w2Yh26N3C/+4XMAHNzaTnj5Mp+CMmFel5RXd/0m1YB0dVkctl6B8egG/3JyI6JhUPNPcz+WuyANq02ANkIxIyy1YSDfJ0RBc/w20QiGqrW2NvbHqxB9qHeCC3sBRPfXMIn24/a7YtNEo1Wvx7IRPv/HYSXefsxIiv9mPVvkSk5xXBVWWHRzoE4avRHRHgpmQdHNXZgJvDYNtj06Axw3s8LqWsAJprAJkGe4BsREJm2fBEWSFdnrTBUL2idnfED891w+zNsfh2fyL+b+c5HL98DZ8NbwcPJ+Ovmluq0WL/xWxsiUlBdEwqsvKL9Y+5qezQPyIAg1qrcW8Tbyjtyvbu0kJg4pojkAEGxdCsg6Oa6BLmBXdHe2TlF+NQQja6NvK++5NqKT2vEJnXiyCXAS0COARmCkyAbET8zfqMUG/OJCDjc7CTY/bQVmgX7IG3fj2J3WcyMHjhP1g6uiMiAuvefV+i0WLfhSz8EZOC6FNpyL4t6fFwskf/cH8MbK3GvY194GBXvmN7QCs1lozucNs6QGUC3FWYOTicdXBULfYKOfq29McvRy5j66lUkyZAuuGvMB9nODpwE15TYAJkI/Q9QN5OwDVpY6H669GODdBC7YoJaw7jUvYNPLL4X8x5uDUe7dgAQFmdzsH4bKTnFcLPtWzYqbKel+LSsuGtLSdTsC02DdcKbm3K6uXsgMgIfzzYSo1ujb1hr7j7aP6AVmr0Cw/AvvPp2Pb3AfTvyTo4qrnIiLIEaNupNLz7UDhkMtO8f24VQLP+x1SYANkI3W7Cod5OuHFN2liofosIdMemyT3w8g/HsPtMBl796TiOXbqGLmFemLMlzqAHRn1HD0xxqRb/nM/AlpOp2HYqFbmFpfpzvZ0dENmqbHira5gX7KqR9NxJIZeha5gXsuJYB0e1c18zXzjaK3Dl2g3EXMlF6wamSVBY/2N6TIBsgBBCP0U51NsJcRckDojqPQ8nB6wY2xn/t/Mc/m/nOXy7PxHf7k8sd15qTiEmrjmCCb0aIy23ENvj0pB3W9Lj46LEg60C8GDrAHQN82bCQpJT2SvwQAtfbDmZiuhTqSZLgGKTcwAA4WrW/5gKEyAbkJ5XhIJiDeQyIMjDEXFSB0Q2QS6X4ZV+zdA6yA3Prj5c4UrMumNL9tzKyv1cy5Kega3V6BTKXhqyPJERAdhyMhVbT6XitcjmRr9+QXEpLt4sW+AaQKbDBMgGxN/8RWrg6VRhgSiRKTkr7avchkJnQCt/PN2jETqGeHLVW7JoD7Twg71ChvPp13E+/Tqa+LkY9fpnUvMgRFkPKNenMh1+GtoAXQF0qI+zxJGQLaruCssPtlKjc6gXkx+yeG4qe9zb2AeAafYGY/2PeTABsgG6AugwToEnCVT3L1j+pUvWRLcooikSoNiUm/U/HP4yKSZANuDWFHj2AJH5dQnzgtpdxZWYqV7p29IfMhlw4nIOrly7YdRr39oCgwmQKTEBsgEJN2eAhXEIjCSgkMswc3A4AJRLgrgSM1krX1clOjcsS9q3GbEXSKsVOJ1aNgQWwR4gk2ICVM9ptUKfALEGiKSiW4k5wN1wmCvAXYUloztwJWaySpEmGAZLzC5AQbEGSjs5Qtlrb1KcBVbPpecVobBEC4VchgaejoBWI3VIZKN0KzFXdyVoIkvXP9wfszfH4mB8NrKuF8HbRVnna+qGv1oEuNZqsU+qPiZA9ZxuCnywpyPsFXKUMAEiCSnkMnRrbLr9k4jMKdjLCa2C3BBzJRc74tIwvHNIna/JAmjzYXpZz+mGv1gATURkfJHhumGwNKNcjwXQ5sMEqJ7TzQBjATQRkfHppsP/cy4TeYUldzn77m6tAcQEyNSYANVzuiGwUK4BRERkdE38XNDIxxnFGi12n8mo07WyrhchNbds4dAWTIBMjglQPZeo2wWePUBEREYnk8n0s8G21nE2mK73J9TbCS5KluiaGhOgeuz2KfAcAiMiMo0BEWUJ0O7T6Sgsqf1EExZAmxcToHosNbcQRaVa2MllCPJwlDocIqJ6qU0Dd6jdVcgv1mDv+cxaX0fXA8QCaPOoUQJ08OBBaDS3stvNmzejV69eCAoKQqdOnbB69WqjB0i1pyuADvZy4noSREQmIpPJEHmzF2hrTO2HwXQzwFgAbR41+lTs1q0bsrKyAACbNm3CkCFDEBoairfffhvt27fH008/jV9//dUkgVLNxWexAJqIyBz6R/gDAHbEpaFUo63x8wtLNDifcR0Ah8DMpUZVVkII/X/PmzcPb7zxBj788EP9sbCwMMybNw8PP/yw8SKkWmMBNBGReXQJ9YKnkz2uFpTgYEI27m3sU6Pnn0u7Do1WwNPJHgFuqrs/geqs1uMiZ8+exbBhwwyOPfroozh9+nSdgyLjuDUFngkQEZEp2Snk6NuyrBdoWy0WRYxLubkAYqAbZDJuD2MONU6AYmNjceLECTg6OkKrLd/NV1paapTAqO50NUDsASIiMr0Bt22OevuISXXE3kyAWgZw+MtcapwA9enTB+3atUNSUhL27t1r8NjRo0cRElL3vVCo7rRagcTssiGwMPYAERGZXPcmPnB2UCAlpxAnLufU6Ln6LTBY/2M2NaoBio+PN/jexcXF4Pvi4mJMmzat7lFRnaXkFqK4VAt7hQyBHhxPJiIyNZW9Ave38MPvJ1Kw9VQq2gZ7VOt5QgiDITAyjxolQA0bNqzy8TFjxtQpGDIeToEnIjK/AREB+P1ECqJjUvFGZPNq1fNcvnoDeUWlcFDI0djX5a7nk3Hwk7GeYgE0EZH53d/cFw4KOS5m5uN8+vVqPefUzeGvpv4usOcfrGZj1Dvdt29fNGrUyJiXpFpKYAJERGR2rip79GhaNgW+uosi6gqguQK0eRk1AXr44YcxduxYY16SaunWHmBcBJGIyJwiby6KGB1bzQSIBdCSMOp2s5MmTTLm5agOErgIIhGRJPq29IdcdhIxV3JxKbsAwV5V/yEaxx4gSdSpB6ioqAhFRUXGioWMRKMVSNIlQBwCIyIyK28XJbqEeQEAtsVWvShiTkEJrly7AQBowQTIrGqcAG3fvh0DBw6Ep6cnnJyc4OTkBE9PTwwcOBA7duwwRYxUQ8nXbqBYo4WDQo5A7gJPRGR2us1Ro+9SB6Sr/2ng6Qh3R3uTx0W31CgBWrVqFQYOHAh3d3d8+umn2Lx5MzZv3oxPP/0UHh4eGDhwIL799ltTxUrVpKv/CfZyhELOJdWJiMxNlwD9l5iNjLzKR0pYAC2dGtUAffDBB/jss88qrPUZN24cevTogffeew9PPvmk0QKkmtPNAAtj/Q8RkSQCPRzRpoE7TlzOwY64NIzsUvEuCVwAUTo16gFKSkpC3759K328T58+uHz5cp2DorpJYP0PEZHkdL1AVU2H180Aa8keILOrUQIUERGB5cuXV/r4ihUrEB4eXuegqG50PUAN2QNERCQZXQL074VM5BaWlHu8uFSLc+l5ADgEJoUaDYF98skneOihh7B161b07dsX/v5lax2kpaVh586duHjxIn7//XeTBErVF69bA4g9QEREkmni54Imfi44n34du06nY0i7IIPHz6dfR4lGwFVlhwaenLBibjVKgO6//37ExMRgyZIl2L9/P1JTy7r1AgIC8OCDD2LChAkIDQ01RZxUTaUaLS5l69YA4iKIRERSiozwx/n064g+lVouAbp9/Z/q7BlGxlXjhRBDQ0Mxd+5cU8RCRpCSU4gSjYCDnRyB7vyLgohISgMi1Fi06wJ2nc5AYYkGKnuF/jHdDDDW/0ijTgshnj17FgcOHEBmZqax4qE60m2C2tDLCXJOgSciklSrIDcEeTjiRokGf53NMHiMW2BIq1YJ0Pr169GoUSP069cPL730Epo1a4ann34axcXFxo6Paki3BlBD1v8QEUlOJpOhv25vsFO3VoUWQnANIInVOAFavHgxXn/9dXz99ddITEzEgQMHcOnSJeTn5+Ptt98GANy4ccPogVL1xGdyE1QiIksy4OZssB1xaSjRaAGUlSvk3CiBnVyGpv4uUoZns2qUAMXGxmLGjBnYvn07mjVrhqSkJCQlJSErKwuvvfYavv76awgh0KNHDxw7dsxEIVNVdFPguQkqEZFl6BTqBW9nB+TcKMHB+GwAt4a/mvi5QGmnqOrpZCI1SoAWLlyIZ555Bo0aNULfvn3RpEkThIaGIjQ0FF27doWLiwvS09MxevRoREVFmSpmqkLizUUQOQWeiMgyKOQy9AsvGwbTLYrI4S/p1SgB2r17NwYOHAgAmDx5MgYMGIDLly/j6tWrePXVVzFo0CD4+/vjiSeeQHR0NEpKyi/8RKZTqtEiST8FngkQEZGl0C2KuC02FVqtYAG0BajRNPj09HT4+fkBABYsWID169cjMDAQQNk+YS4uLvjoo4/g5+cHrVaL9PR0BAUFVXVJMqIr126gVCugtJMjwE0ldThERHTTvU284aK0Q1puEY5dvsYeIAtQox4gT09P/V5fdnZ2OHPmjP6xixcvorS0FPb29rhx4waKi4vh5sYfrDnpp8B7cwo8EZElUdop0LtFWQfCL4cv63vruQaQdGqUAHXv3h07d+4EALzyyit4+umnMWHCBLz66qt44IEH8Nxzz8HZ2Rl//vknmjVrBldXV5METRXTF0Cz/oeIyOLohsHW/ZcEAPBytoebo72UIdm0GiVAEyZMwLJly5CRkYGJEyfijz/+gLu7O7RaLb744gssWbIEWq0Wc+bMwcSJE00VM1VCtwt8GOt/iIgsjm4K/M3/Q3Z+CXrM/RNbY1IkjMp21SgBuueeezBq1CgMHjwYaWlp6NmzJ+bOnYtPP/0Ujz76KDQaDZ5++mkIITBp0qRqXXPRokUIDQ2FSqVC165dcfDgwSrPv3btGiZNmgS1Wg2lUolmzZphy5Yt+sdnzZoFmUxm8NWiRYuaNNNqcRFEIiLLtDUmBa/8cKzc8dScQkxcc4RJkARqvBfY559/jjfeeANt2rTB2LFjce+998LR0REnT57EsmXL0LRpU2zZsgV2dne/9A8//ICpU6di6dKl6Nq1Kz777DNERkbizJkz+mLr2xUXF6Nfv37w8/PDzz//jKCgICQmJsLDw8PgvIiICOzYseNWI6sRS31waw0gLoJIRGQpNFqBqE2xEBU8JgDIAERtikW/8AAoWL9pNjXODGQyGebPn4/x48dj7dq1WLlyJUpLS9GkSRN8+eWXuP/++6t9rQULFuDZZ5/F+PHjAQBLly7F77//jhUrVuDNN98sd/6KFSuQnZ2Nf//9F/b2ZeOmFe0+b2dnh4CAgJo2zaqVaLS4dLVsBW4OgRERWY6D8dlIySms9HGBspWhD8Zno1tjb/MFZuNq3TUSHh6O999/v9YvXFxcjMOHD2P69On6Y3K5HH379sW+ffsqfM7GjRvRrVs3TJo0CRs2bICvry9GjRqFadOmQaG4tZLmuXPnEBgYCJVKhW7duuHDDz9ESEhIrWO1Bleu3oBGK6Cyl8PflVPgiYgsRXpe5clPbc4j46hRAqTVajF//nxs3LgRxcXF6NOnD2bOnAlHR8cav3BmZiY0Gg38/f0Njvv7++P06dMVPufixYv4888/8cQTT2DLli04f/48XnjhBZSUlGDmzJkAgK5du+Kbb75B8+bNkZKSgqioKPTs2RMxMTGVzkorKipCUVGR/vvc3LL1GUpKSqxmMcfzaTkAynaB12hKodFUfJ6uPdbSLmOz9fYDvAdsv223HzD/PfB2qt5HrbeTnVliqs/vgZq0SSaEqGhYskKzZ8/GrFmz0LdvXzg6OiI6OhojR47EihUrahxkcnIygoKC8O+//6Jbt27642+88Qb27NmDAwcOlHtOs2bNUFhYiPj4eH2Pz4IFCzB//nykpFRcQHbt2jU0bNgQCxYswNNPP13hObNmzapw6461a9fCyck66mn2pMiwPkGBNl5aPN1cK3U4RER0k1YAUUcUuFYMlFX83EnAwwGY2UEDlgDVTUFBAUaNGoWcnJy7rkVYox6g1atXY/HixXj++ecBADt27MCgQYPw9ddfQy6v2cbyPj4+UCgUSEtLMzielpZWaf2OWq2Gvb29wXBXy5YtkZqaiuLiYjg4OJR7joeHB5o1a4bz589XGsv06dMxdepU/fe5ubkIDg5G//79rWYxx0Ob44CES+ga3ggDI5tVel5JSQm2b9+Ofv366euobImttx/gPWD7bbv9gDT3wD40DS+uOw4ABsXQspv/+/4jbREZ4V/BM42vPr8HdCM41VGjBCgpKUm/FxgA9O3bFzKZDMnJyWjQoEFNLgUHBwd07NgRO3fuxNChQwGUDbHt3LkTkydPrvA53bt3x9q1a6HVavUJ19mzZ6FWqytMfgDg+vXruHDhAp588slKY1EqlVAqleWO29vbW82bI/Fq2dhxYz/XasVsTW0zBVtvP8B7wPbbdvsB896Dh9o1gJ2dAlGbYg0KogPcVZg5OBwDWqnNEsft6uN7oCbtqVECVFpaCpXKsMDW3t6+1uOIU6dOxdixY9GpUyd06dIFn332GfLz8/WzwsaMGYOgoCB8+OGHAICJEydi4cKFmDJlCl588UWcO3cOc+bMwUsvvaS/5muvvYbBgwejYcOGSE5OxsyZM6FQKDBy5MhaxWgtErN0U+A5A4yIyBINaKVGv/AAHIzPRnpeIfxcVegS5sWp7xKpUQIkhMC4ceMMeksKCwsxYcIEODvf+uBdv359ta43fPhwZGRk4N1330VqairatWuHrVu36gujk5KSDIbWgoODER0djVdeeQVt2rRBUFAQpkyZgmnTpunPuXz5MkaOHImsrCz4+vqiR48e2L9/P3x9fWvSVKtSotHiMqfAExFZPIVcxqnuFqJGCdDYsWPLHRs9enSdApg8eXKlQ167d+8ud6xbt27Yv39/pddbt25dneKxRpeyC6DRCjjaK+DnWn4oj4iIiAzVKAFauXKlqeKgOri1BYYTZDJ2pRIREd1NzaZuVUEIgT/++APDhg0z1iWpmuIzuQkqERFRTdQ5AYqPj8eMGTMQEhKChx9+GIWFXMnS3FgATUREVDO12gqjqKgIP//8M5YvX45//vkHGo0GH3/8MZ5++mmrWTenPom/uQlqGHeBJyIiqpYa9QAdPnwYL7zwAgICAvDZZ59h6NChuHTpEuRyOSIjI5n8SOT2GiAiIiK6uxr1AHXt2hUvvvgi9u/fj+bNm5sqJqqB4lItrnAKPBERUY3UKAHq06cPli9fjvT0dDz55JOIjIzkrCOJXbpaAK0AnB0U8OUUeCIiomqp0RBYdHQ0Tp06hebNm2PixIlQq9WYMmUKADARkkhCpm74y5k/AyIiomqq8Syw4OBgvPvuu4iPj8e3336LjIwM2NnZYciQIXjrrbdw+PBhU8RJldAVQIf6sP6HiIiouuo0Db5fv35Yu3YtkpOT8dJLL+GPP/5Aly5djBUbVYOuADqUM8CIiIiqrVbT4IGyPcBOnDiB9PR0aLVahISEICoqChcuXDBmfHQXCTcXQeQaQERERNVXqwRo69atGDNmDDIzM8s9JpPJ8Morr9Q5MKoeXQ8QZ4ARERFVX62GwF588UU89thjSElJgVarNfjSaDTGjpEqUVSqQfK1sinwHAIjIiKqvlolQGlpaZg6dSr8/f2NHQ/VwKXsW1PgfVwcpA6HiIjIatQqARo2bBh2795t5FCopuJvq//hFHgiIqLqq1UN0MKFC/HYY4/h77//RuvWrWFvb2/w+EsvvWSU4KhqCZncBJWIiKg2apUAff/999i2bRtUKhV2795t0Psgk8mYAJmJvgCa9T9EREQ1UqsE6O2330ZUVBTefPNNyOV1WkqI6kC/BhB7gIiIiGqkVtlLcXExhg8fzuRHYvo1gLgLPBERUY3UKoMZO3YsfvjhB2PHQjVQWKJBcs7NKfDsASIiIqqRWg2BaTQazJs3D9HR0WjTpk25IugFCxYYJTiqXFJ2AYQAXJV28HbmFHgiIqKaqFUCdPLkSbRv3x4AEBMTY/AYp2Obx+0zwHjPiYiIaqZWCdCuXbuMHQfVkK4AuiHrf4iIiGqMVcxWSrcIIvcAIyIiqjkmQFZKPwTGNYCIiIhqjAmQlUrkGkBERES1xgTICpVNgS8EwCEwIiKi2mACZIUSs8rqf1xVdvB0sr/L2URERHQnJkBWKP5m/U8Yp8ATERHVChMgK6TfA4wF0ERERLXCBMgKsQCaiIiobpgAWaFbQ2BcBJGIiKg2mABZId0u8A05BEZERFQrTICszI1iDVJzb06BZwJERERUK0yArIyuANrd0R6e3AWeiIioVpgAWRkWQBMREdUdEyAro9sENZS7wBMREdUaEyArw01QiYiI6o4JkJWJz7q1CjQRERHVDhMgK8MaICIiorpjAmRFCopLkZZbBIBT4ImIiOqCCZAV0S2A6OFkD3fuAk9ERFRrTICsCDdBJSIiMg4mQFbk1h5gTICIiIjqggmQFUlkDxAREZFRMAGyIroaoFDuAk9ERFQnTICsSDx7gIiIiIyCCZCVuF5Uioy8sinwXAOIiIiobpgAWQndFhhezg5wd+QUeCIiorpgAmQlErO4CSoREZGxMAGyElwDiIiIyHiYAFkJ3RpArP8hIiKqOyZAViKBCRAREZHRMAGyEgk3a4C4CSoREVHdMQGyAnmFJci8XjYFviEXQSQiIqozJkBWQDcDzNvZAW4qToEnIiKqKyZAVoAF0ERERMbFBMgK6AugWf9DRERkFEyArIC+AJr1P0REREbBBMgK6BdB5BAYERGRUUieAC1atAihoaFQqVTo2rUrDh48WOX5165dw6RJk6BWq6FUKtGsWTNs2bKlTte0dBwCIyIiMi5JE6AffvgBU6dOxcyZM3HkyBG0bdsWkZGRSE9Pr/D84uJi9OvXDwkJCfj5559x5swZLFu2DEFBQbW+pqXLLSxBVn4xAPYAERERGYukCdCCBQvw7LPPYvz48QgPD8fSpUvh5OSEFStWVHj+ihUrkJ2djd9++w3du3dHaGgoevXqhbZt29b6mpZO1/vj46KEi9JO4miIiIjqB8k+UYuLi3H48GFMnz5df0wul6Nv377Yt29fhc/ZuHEjunXrhkmTJmHDhg3w9fXFqFGjMG3aNCgUilpdEwCKiopQVFSk/z43NxcAUFJSgpKSkro2tU4upJXFEurtaJRYdNeQul1SsfX2A7wHbL9ttx/gPajP7a9JmyRLgDIzM6HRaODv729w3N/fH6dPn67wORcvXsSff/6JJ554Alu2bMH58+fxwgsvoKSkBDNnzqzVNQHgww8/RFRUVLnj27Ztg5OTtDOvtl+WAVBAXpBdrtapTtfdvt1o17JGtt5+gPeA7bft9gO8B/Wx/QUFBdU+16rGVLRaLfz8/PDVV19BoVCgY8eOuHLlCubPn4+ZM2fW+rrTp0/H1KlT9d/n5uYiODgY/fv3h5ubmzFCr7VdP58ELqWgR9tmGNirUZ2vV1JSgu3bt6Nfv36wt7e9VaVtvf0A7wHbb9vtB3gP6nP7dSM41SFZAuTj4wOFQoG0tDSD42lpaQgICKjwOWq1Gvb29lAoFPpjLVu2RGpqKoqLi2t1TQBQKpVQKpXljtvb20v+5ki8egMA0NjPzaixWELbpGTr7Qd4D9h+224/wHtQH9tfk/ZIVgTt4OCAjh07YufOnfpjWq0WO3fuRLdu3Sp8Tvfu3XH+/HlotVr9sbNnz0KtVsPBwaFW17R0un3AQrkIIhERkdFIOgts6tSpWLZsGVatWoW4uDhMnDgR+fn5GD9+PABgzJgxBgXNEydORHZ2NqZMmYKzZ8/i999/x5w5czBp0qRqX9Oa5NwoQbZuCjzXACIiIjIaSWuAhg8fjoyMDLz77rtITU1Fu3btsHXrVn0Rc1JSEuTyWzlacHAwoqOj8corr6BNmzYICgrClClTMG3atGpf05ropsD7uirhzCnwRERERiP5p+rkyZMxefLkCh/bvXt3uWPdunXD/v37a31Na6LbAiOMvT9ERERGJflWGFS5eN0WGKz/ISIiMiomQBbsVgE0e4CIiIiMiQmQBdP1AHEIjIiIyLiYAFkwXQ1QQyZARERERsUEyEJdKyjGtYKyPU1YA0RERGRcTIAslG74y99NCScHySfrERER1StMgCyUvgCaw19ERERGxwTIQumnwDMBIiIiMjomQBZKVwDNKfBERETGxwTIQum2wQhjATQREZHRMQGyUAlcBJGIiMhkmABZoKv5xci5UTYFvqEXEyAiIiJjYwJkgeJv1v8EuKng6KCQOBoiIqL6hwmQBUrgJqhEREQmxQTIAt0qgObwFxERkSkwAbJACVwEkYiIyKSYAFkgrgFERERkWkyALIwQgqtAExERmRgTIAuTnV+MvMJSAEBDbxZBExERmQITIAujG/4KdFdBZc8p8ERERKbABMjCJGRyBWgiIiJTYwJkYXQ9QA1Z/0NERGQyTIAsTDw3QSUiIjI5JkAWRj8Fnj1AREREJsMEyIIIIZB4swaIq0ATERGZDhMgC5KVX4y8olLIZECwF4fAiIiITIUJkAXR7QEW6O7IKfBEREQmxATIgsRzF3giIiKzYAJkQVgATUREZB5MgCyIbhd4FkATERGZFhMgC5LATVCJiIjMggmQhRBC3EqAWANERERkUkyALETG9SLkF2sg5xR4IiIik2MCZCF0m6AGejhCaccp8ERERKbEBMhC6GaAsQCaiIjI9JgAWQhd/U9Dbw5/ERERmRoTIAvBNYCIiIjMhwmQhYjnJqhERERmwwTIAgghkKjrAWICREREZHJMgCxARl4RCnRT4D1ZA0RERGRqTIAsgG4T1CBPRzjY8UdCRERkavy0tQAsgCYiIjIvJkAWgAXQRERE5sUEyAIksgeIiIjIrJgAWQBdDRB7gIiIiMyDCZDEyqbAlw2BcRVoIiIi82ACJLG03CLcKNFAIZdxF3giIiIzYQIkMd3wVwNPR9gr+OMgIiIyB37iSowF0ERERObHBEhi8foEiMNfRERE5sIESGIJmdwDjIiIyNyYAEks4eYiiEyAiIiIzIcJkIS0WqHfBiOMNUBERERmwwRIQml5hSgq1cJOLkMDT0epwyEiIrIZTIAkdPsUeDtOgSciIjIbfupKiPU/RERE0mACJKEErgFEREQkCSZAEkrgJqhERESSYAIkIX0PEBMgIiIis7KIBGjRokUIDQ2FSqVC165dcfDgwUrP/eabbyCTyQy+VCqVwTnjxo0rd86AAQNM3Ywa0Wpv7QLPVaCJiIjMy07qAH744QdMnToVS5cuRdeuXfHZZ58hMjISZ86cgZ+fX4XPcXNzw5kzZ/Tfy2SycucMGDAAK1eu1H+vVCqNH3wdpOTemgIf5MEp8EREROYkeQ/QggUL8Oyzz2L8+PEIDw/H0qVL4eTkhBUrVlT6HJlMhoCAAP2Xv79/uXOUSqXBOZ6enqZsRo3p6n9CvJw4BZ6IiMjMJO0BKi4uxuHDhzF9+nT9Mblcjr59+2Lfvn2VPu/69eto2LAhtFotOnTogDlz5iAiIsLgnN27d8PPzw+enp7o3bs33n//fXh7e1d4vaKiIhQVFem/z83NBQCUlJSgpKSkLk2s1IX0stcI8XI02WtURPda5nxNS2Lr7Qd4D9h+224/wHtQn9tfkzbJhBDChLFUKTk5GUFBQfj333/RrVs3/fE33ngDe/bswYEDB8o9Z9++fTh37hzatGmDnJwcfPzxx/jrr79w6tQpNGjQAACwbt06ODk5ISwsDBcuXMBbb70FFxcX7Nu3DwqFotw1Z82ahaioqHLH165dCycn09Tn/JYgx64UOXoFaPFImNYkr0FERGRLCgoKMGrUKOTk5MDNza3Kc60uAbpTSUkJWrZsiZEjR2L27NkVnnPx4kU0btwYO3bsQJ8+fco9XlEPUHBwMDIzM+96A2trwndHsfN0BmY+1AKju4aY5DUqUlJSgu3bt6Nfv36wt7c32+taCltvP8B7wPbbdvsB3oP63P7c3Fz4+PhUKwGSdAjMx8cHCoUCaWlpBsfT0tIQEBBQrWvY29ujffv2OH/+fKXnNGrUCD4+Pjh//nyFCZBSqaywSNre3t5kb47E7BsAgMZ+bpK8AU3ZNmtg6+0HeA/YfttuP8B7UB/bX5P2SFp96+DggI4dO2Lnzp36Y1qtFjt37jToEaqKRqPByZMnoVarKz3n8uXLyMrKqvIcc9JoBZJuToHnIohERETmJ/n0o6lTp2LZsmVYtWoV4uLiMHHiROTn52P8+PEAgDFjxhgUSb/33nvYtm0bLl68iCNHjmD06NFITEzEM888A6CsQPr111/H/v37kZCQgJ07d2LIkCFo0qQJIiMjJWnjnVJybqBYo4W9QoZAToEnIiIyO8nXARo+fDgyMjLw7rvvIjU1Fe3atcPWrVv1U9uTkpIgl9/K065evYpnn30Wqamp8PT0RMeOHfHvv/8iPDwcAKBQKHDixAmsWrUK165dQ2BgIPr374/Zs2dbzFpAuk1Qg72coJCXX8OIiIiITEvyBAgAJk+ejMmTJ1f42O7duw2+//TTT/Hpp59Wei1HR0dER0cbMzyji7+5BUYYN0ElIiKShORDYLZItwgi9wAjIiKSBhMgCSRyE1QiIiJJMQGSQHwmh8CIiIikxATIzDRagUs31wBqyF3giYiIJMEEyMySr5VNgXdQyDkFnoiISCJMgMxMN/wV4s0p8ERERFJhAmRm+gJo1v8QERFJhgmQmcXfXAQxlPU/REREkmECZGYJnAJPREQkOSZAZqTRCsQl5wIAbhRroNEKiSMiIiKyTUyAzGRrTAq6f/QnUnILAQAfbIlDj7l/YmtMisSRERER2R4mQGawNSYFE9ccQerN5EcnNacQE9ccYRJERERkZkyATEyjFYjaFIuKBrt0x6I2xXI4jIiIyIyYAJnYwfhspOQUVvq4AJCSU4iD8dnmC4qIiMjGMQEysfS8ypOf2pxHREREdccEyMT8XFVGPY+IiIjqjgmQiXUJ84LaXYXKNr2QAVC7q9AlzMucYREREdk0JkAmppDLMHNwOACUS4J0388cHM59wYiIiMyICZAZDGilxpLRHRDgbjjMFeCuwpLRHTCglVqiyIiIiGyTndQB2IoBrdToFx6Ag/HZSM8rhJ9r2bAXe36IiIjMjwmQGSnkMnRr7C11GERERDaPQ2BERERkc5gAERERkc1hAkREREQ2hwkQERER2RwmQERERGRzmAARERGRzWECRERERDaHCRARERHZHCZAREREZHO4EnQFhBAAgNzcXIkjMb6SkhIUFBQgNzcX9vb2UodjdrbefoD3gO237fYDvAf1uf26z23d53hVmABVIC8vDwAQHBwscSRERERUU3l5eXB3d6/yHJmoTppkY7RaLZKTk+Hq6gqZrH5tVpqbm4vg4GBcunQJbm5uUodjdrbefoD3gO237fYDvAf1uf1CCOTl5SEwMBByedVVPuwBqoBcLkeDBg2kDsOk3Nzc6t0bvyZsvf0A7wHbb9vtB3gP6mv779bzo8MiaCIiIrI5TICIiIjI5jABsjFKpRIzZ86EUqmUOhRJ2Hr7Ad4Dtt+22w/wHth6+3VYBE1EREQ2hz1AREREZHOYABEREZHNYQJERERENocJEBEREdkcJkA24MMPP0Tnzp3h6uoKPz8/DB06FGfOnJE6LEl99NFHkMlkePnll6UOxWyuXLmC0aNHw9vbG46OjmjdujUOHTokdVhmo9FoMGPGDISFhcHR0RGNGzfG7Nmzq7VnkDX666+/MHjwYAQGBkImk+G3334zeFwIgXfffRdqtRqOjo7o27cvzp07J02wJlLVPSgpKcG0adPQunVrODs7IzAwEGPGjEFycrJ0ARvZ3d4Dt5swYQJkMhk+++wzs8UnNSZANmDPnj2YNGkS9u/fj+3bt6OkpAT9+/dHfn6+1KFJ4r///sOXX36JNm3aSB2K2Vy9ehXdu3eHvb09/vjjD8TGxuKTTz6Bp6en1KGZzdy5c7FkyRIsXLgQcXFxmDt3LubNm4cvvvhC6tBMIj8/H23btsWiRYsqfHzevHn4/PPPsXTpUhw4cADOzs6IjIxEYWGhmSM1naruQUFBAY4cOYIZM2bgyJEjWL9+Pc6cOYP//e9/EkRqGnd7D+j8+uuv2L9/PwIDA80UmYUQZHPS09MFALFnzx6pQzG7vLw80bRpU7F9+3bRq1cvMWXKFKlDMotp06aJHj16SB2GpAYNGiSeeuopg2OPPPKIeOKJJySKyHwAiF9//VX/vVarFQEBAWL+/Pn6Y9euXRNKpVJ8//33EkRoenfeg4ocPHhQABCJiYnmCcqMKmv/5cuXRVBQkIiJiRENGzYUn376qdljkwp7gGxQTk4OAMDLy0viSMxv0qRJGDRoEPr27St1KGa1ceNGdOrUCY899hj8/PzQvn17LFu2TOqwzOree+/Fzp07cfbsWQDA8ePH8c8//+DBBx+UODLzi4+PR2pqqsHvgbu7O7p27Yp9+/ZJGJm0cnJyIJPJ4OHhIXUoZqHVavHkk0/i9ddfR0REhNThmB03Q7UxWq0WL7/8Mrp3745WrVpJHY5ZrVu3DkeOHMF///0ndShmd/HiRSxZsgRTp07FW2+9hf/++w8vvfQSHBwcMHbsWKnDM4s333wTubm5aNGiBRQKBTQaDT744AM88cQTUodmdqmpqQAAf39/g+P+/v76x2xNYWEhpk2bhpEjR9bLDUIrMnfuXNjZ2eGll16SOhRJMAGyMZMmTUJMTAz++ecfqUMxq0uXLmHKlCnYvn07VCqV1OGYnVarRadOnTBnzhwAQPv27RETE4OlS5faTAL0448/4rvvvsPatWsRERGBY8eO4eWXX0ZgYKDN3AOqWElJCR5//HEIIbBkyRKpwzGLw4cP4//+7/9w5MgRyGQyqcORBIfAbMjkyZOxefNm7Nq1Cw0aNJA6HLM6fPgw0tPT0aFDB9jZ2cHOzg579uzB559/Djs7O2g0GqlDNCm1Wo3w8HCDYy1btkRSUpJEEZnf66+/jjfffBMjRoxA69at8eSTT+KVV17Bhx9+KHVoZhcQEAAASEtLMzielpamf8xW6JKfxMREbN++3WZ6f/7++2+kp6cjJCRE/29iYmIiXn31VYSGhkodnlmwB8gGCCHw4osv4tdff8Xu3bsRFhYmdUhm16dPH5w8edLg2Pjx49GiRQtMmzYNCoVCosjMo3v37uWWPjh79iwaNmwoUUTmV1BQALnc8G8+hUIBrVYrUUTSCQsLQ0BAAHbu3Il27doBAHJzc3HgwAFMnDhR2uDMSJf8nDt3Drt27YK3t7fUIZnNk08+Wa4WMjIyEk8++STGjx8vUVTmxQTIBkyaNAlr167Fhg0b4Orqqh/jd3d3h6Ojo8TRmYerq2u5midnZ2d4e3vbRC3UK6+8gnvvvRdz5szB448/joMHD+Krr77CV199JXVoZjN48GB88MEHCAkJQUREBI4ePYoFCxbgqaeekjo0k7h+/TrOnz+v/z4+Ph7Hjh2Dl5cXQkJC8PLLL+P9999H06ZNERYWhhkzZiAwMBBDhw6VLmgjq+oeqNVqDBs2DEeOHMHmzZuh0Wj0/zZ6eXnBwcFBqrCN5m7vgTsTPnt7ewQEBKB58+bmDlUaUk9DI9MDUOHXypUrpQ5NUrY0DV4IITZt2iRatWollEqlaNGihfjqq6+kDsmscnNzxZQpU0RISIhQqVSiUaNG4u233xZFRUVSh2YSu3btqvD3fuzYsUKIsqnwM2bMEP7+/kKpVIo+ffqIM2fOSBu0kVV1D+Lj4yv9t3HXrl1Sh24Ud3sP3MnWpsHLhKiny6ASERERVYJF0ERERGRzmAARERGRzWECRERERDaHCRARERHZHCZAREREZHOYABEREZHNYQJERERENocJEBERgHHjxtWrVZCJqGpMgIjI4o0bNw4ymazc14ABA6QOjYisFPcCIyKrMGDAAKxcudLgmFKplCgaIrJ27AEiIqugVCoREBBg8OXp6QkAkMlkWLJkCR588EE4OjqiUaNG+Pnnnw2ef/LkSfTu3RuOjo7w9vbGc889h+vXr5d7nY8//hhqtRre3t6YNGkSSkpK9I99++236NSpE1xdXREQEIBRo0YhPT3dtA0nIpNgAkRE9cKMGTPw6KOP4vjx43jiiScwYsQIxMXFAQDy8/MRGRkJT09P/Pfff/jpp5+wY8cOTJ482eAau3btwoULF7Br1y6sWrUK33zzDb755hv94yUlJZg9ezaOHz+O3377DQkJCRg3bpwZW0lExsLNUInI4o0bNw5r1qyBSqUyOP7WW2/hrbfegkwmw4QJE7BkyRL9Y/fccw86dOiAxYsXY9myZZg2bRouXboEZ2dnAMCWLVswePBgJCcnw9/fH+PGjcPu3btx4cIFKBQKAMDjjz8OuVyOdevWVRjXoUOH0LlzZ+Tl5cHFxcVErSciU2ANEBFZhQceeMAgwQEALy8v/X9369bN4LFu3brh2LFjAIC4uDi0bdtWn/wAQPfu3aHVanHmzBn4+/sDACIiIvTJDwCo1WqcPHlS//3hw4cxa9YsHD9+HFevXoVWqwUAJCUlITw83DgNJSKzYAJERFbB2dkZTZo0Melr2NvbG3wvk8n0SY5uGC0yMhLfffcdfH19kZSUhMjISBQXF5s0LiIyPtYAEVG9sH///nLft2zZEgDQsmVLHD9+HPn5+frH9+7dC7lcjubNm1fr+qdPn0ZWVhY++ugj9OzZEy1atGABNJEVYwJERFahqKgIqampBl+ZmZn6x3/66SesWLECZ8+excyZM3Hw4EF9kfMTTzwBlUqFsWPHIiYmBrt27cKLL76IJ598Uj/8dTchISFwcHDAF198gYsXL2Ljxo2YPXu2SdpKRKbHBIiIrMLWrVuhVqsNvnr06KF/PCoqCuvWrUObNm2wevVqfP/99/q6HCcnJ0RHRyM7OxudO3fGsGHD0KdPHyxcuLDar+/r64tvvvkGP/30E8LDw/HRRx/h448/Nno7icg8OAuMiKyeTCbDr7/+yq0siKja2ANERERENocJEBEREdkcToMnIqvHkXwiqin2ABEREZHNYQJERERENocJEBEREdkcJkBERERkc5gAERERkc1hAkREREQ2hwkQERER2RwmQERERGRzmAARERGRzfl/cqmwMlw5gT8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r runs/custom_loop /content/drive/MyDrive/yolov8_base/"
      ],
      "metadata": {
        "id": "YHj1SYhFBWh5"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}